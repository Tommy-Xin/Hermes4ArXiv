#!/usr/bin/env python3
"""
AIåˆ†æå™¨é€‚é…å™¨
æä¾›ä¸ç°æœ‰ä»£ç çš„å…¼å®¹æ€§ï¼ŒåŒæ—¶æ”¯æŒæ–°çš„å¤šAIåŠŸèƒ½
"""

import asyncio
import logging
from typing import Dict, Any
import arxiv

from multi_ai_analyzer import MultiAIAnalyzer
from ai_prompts import PromptManager

logger = logging.getLogger(__name__)


class AIAnalyzerAdapter:
    """AIåˆ†æå™¨é€‚é…å™¨ï¼Œå…¼å®¹ç°æœ‰æ¥å£"""
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            config: é…ç½®å¯¹è±¡
        """
        self.config = config
        self.multi_analyzer = None
        self.analysis_type = getattr(config, 'ANALYSIS_TYPE', 'comprehensive')
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¤šAIåŠŸèƒ½
        self.enable_multi_ai = self._should_enable_multi_ai()
        
        if self.enable_multi_ai:
            self._initialize_multi_ai()
        else:
            self._initialize_legacy_ai()
    
    def _should_enable_multi_ai(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¯ç”¨å¤šAIåŠŸèƒ½"""
        # å¦‚æœé…ç½®äº†å¤šä¸ªAI APIå¯†é’¥ï¼Œæˆ–è€…æ˜ç¡®è®¾ç½®äº†åˆ†æç­–ç•¥ï¼Œåˆ™å¯ç”¨å¤šAI
        ai_keys = [
            getattr(self.config, 'DEEPSEEK_API_KEY', None),
            getattr(self.config, 'OPENAI_API_KEY', None),
            getattr(self.config, 'CLAUDE_API_KEY', None),
            getattr(self.config, 'GEMINI_API_KEY', None),
        ]
        
        # ç»Ÿè®¡æœ‰æ•ˆçš„APIå¯†é’¥æ•°é‡
        valid_keys = sum(1 for key in ai_keys if key and len(key) > 10)
        
        # å¦‚æœæœ‰å¤šä¸ªAPIå¯†é’¥ï¼Œæˆ–è€…æ˜ç¡®è®¾ç½®äº†åˆ†æç­–ç•¥ï¼Œå¯ç”¨å¤šAI
        strategy = getattr(self.config, 'ANALYSIS_STRATEGY', 'fallback')
        
        return valid_keys > 1 or strategy != 'fallback'
    
    def _initialize_multi_ai(self):
        """åˆå§‹åŒ–å¤šAIåˆ†æå™¨"""
        try:
            # å°†é…ç½®å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
            config_dict = {}
            for attr in dir(self.config):
                if not attr.startswith('_'):
                    config_dict[attr] = getattr(self.config, attr)
            
            self.multi_analyzer = MultiAIAnalyzer(config_dict)
            logger.info("âœ… å¤šAIåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
            
            # æ‰“å°åˆ†æå™¨çŠ¶æ€
            status = self.multi_analyzer.get_analyzer_status()
            available_analyzers = [name for name, info in status['analyzers'].items() if info['available']]
            logger.info(f"ğŸ¤– å¯ç”¨çš„AIåˆ†æå™¨: {available_analyzers}")
            logger.info(f"ğŸ“‹ åˆ†æç­–ç•¥: {status['strategy']}")
            
        except Exception as e:
            logger.error(f"âŒ å¤šAIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.info("ğŸ”„ é™çº§åˆ°ä¼ ç»Ÿå•AIæ¨¡å¼")
            self.enable_multi_ai = False
            self._initialize_legacy_ai()
    
    def _initialize_legacy_ai(self):
        """åˆå§‹åŒ–ä¼ ç»Ÿå•AIåˆ†æå™¨"""
        from ai_analyzer import AnalyzerFactory
        
        try:
            self.legacy_analyzer = AnalyzerFactory.create_analyzer(
                "deepseek",
                api_key=self.config.DEEPSEEK_API_KEY,
                model=getattr(self.config, 'AI_MODEL', 'deepseek-chat'),
                retry_times=self.config.API_RETRY_TIMES,
                delay=self.config.API_DELAY,
            )
            logger.info("âœ… ä¼ ç»ŸAIåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ ä¼ ç»ŸAIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def analyze_paper(self, paper: arxiv.Result) -> str:
        """
        åˆ†æè®ºæ–‡ï¼ˆåŒæ­¥æ¥å£ï¼Œå…¼å®¹ç°æœ‰ä»£ç ï¼‰
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
        
        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        if self.enable_multi_ai:
            return self._analyze_with_multi_ai(paper)
        else:
            return self._analyze_with_legacy_ai(paper)
    
    def _analyze_with_multi_ai(self, paper: arxiv.Result) -> str:
        """ä½¿ç”¨å¤šAIåˆ†æå™¨åˆ†æè®ºæ–‡"""
        try:
            # è¿è¡Œå¼‚æ­¥åˆ†æ
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            try:
                result = loop.run_until_complete(
                    self.multi_analyzer.analyze_paper(paper, self.analysis_type)
                )
                
                # æå–åˆ†ææ–‡æœ¬
                analysis_text = result.get('analysis', '')
                provider = result.get('provider', 'unknown')
                model = result.get('model', 'unknown')
                
                logger.info(f"âœ… å¤šAIåˆ†æå®Œæˆï¼Œä½¿ç”¨: {provider} ({model})")
                
                # å¦‚æœæœ‰é”™è¯¯ï¼Œè®°å½•ä½†ä»è¿”å›ç»“æœ
                if 'error' in result:
                    logger.warning(f"âš ï¸ åˆ†æè¿‡ç¨‹ä¸­æœ‰é”™è¯¯: {result['error']}")
                
                return analysis_text
                
            finally:
                loop.close()
                
        except Exception as e:
            logger.error(f"âŒ å¤šAIåˆ†æå¤±è´¥: {e}")
            # é™çº§åˆ°ä¼ ç»Ÿåˆ†æå™¨
            logger.info("ğŸ”„ é™çº§åˆ°ä¼ ç»ŸAIåˆ†æå™¨")
            return self._analyze_with_legacy_ai(paper)
    
    def _analyze_with_legacy_ai(self, paper: arxiv.Result) -> str:
        """ä½¿ç”¨ä¼ ç»ŸAIåˆ†æå™¨åˆ†æè®ºæ–‡"""
        try:
            analysis = self.legacy_analyzer.analyze_paper(paper)
            logger.info("âœ… ä¼ ç»ŸAIåˆ†æå®Œæˆ")
            return analysis
        except Exception as e:
            logger.error(f"âŒ ä¼ ç»ŸAIåˆ†æå¤±è´¥: {e}")
            # è¿”å›é”™è¯¯åˆ†æ
            return PromptManager.get_error_analysis(str(e))
    
    async def analyze_paper_async(self, paper: arxiv.Result) -> Dict[str, Any]:
        """
        å¼‚æ­¥åˆ†æè®ºæ–‡ï¼ˆæ–°æ¥å£ï¼Œæä¾›æ›´å¤šä¿¡æ¯ï¼‰
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
        
        Returns:
            è¯¦ç»†çš„åˆ†æç»“æœ
        """
        if self.enable_multi_ai:
            return await self.multi_analyzer.analyze_paper(paper, self.analysis_type)
        else:
            # å°†ä¼ ç»Ÿåˆ†æå™¨çš„ç»“æœåŒ…è£…æˆæ–°æ ¼å¼
            try:
                analysis = self.legacy_analyzer.analyze_paper(paper)
                return {
                    'analysis': analysis,
                    'provider': 'deepseek',
                    'model': getattr(self.config, 'AI_MODEL', 'deepseek-chat'),
                    'timestamp': asyncio.get_event_loop().time(),
                    'html_analysis': PromptManager.format_analysis_for_html(analysis)
                }
            except Exception as e:
                error_analysis = PromptManager.get_error_analysis(str(e))
                return {
                    'analysis': error_analysis,
                    'provider': 'error',
                    'model': 'none',
                    'timestamp': asyncio.get_event_loop().time(),
                    'html_analysis': PromptManager.format_analysis_for_html(error_analysis),
                    'error': str(e)
                }
    
    def get_analyzer_info(self) -> Dict[str, Any]:
        """è·å–åˆ†æå™¨ä¿¡æ¯"""
        if self.enable_multi_ai:
            status = self.multi_analyzer.get_analyzer_status()
            return {
                'type': 'multi_ai',
                'status': status,
                'analysis_type': self.analysis_type
            }
        else:
            return {
                'type': 'legacy',
                'provider': 'deepseek',
                'model': getattr(self.config, 'AI_MODEL', 'deepseek-chat'),
                'analysis_type': self.analysis_type
            }
    
    def test_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•AIè¿æ¥"""
        if self.enable_multi_ai:
            available_analyzers = self.multi_analyzer.get_available_analyzers()
            return {
                'multi_ai_enabled': True,
                'available_analyzers': [analyzer.value for analyzer in available_analyzers],
                'total_analyzers': len(self.multi_analyzer.analyzers),
                'strategy': self.multi_analyzer.strategy.value
            }
        else:
            # æµ‹è¯•ä¼ ç»Ÿåˆ†æå™¨
            try:
                # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€å•çš„è¿æ¥æµ‹è¯•
                return {
                    'multi_ai_enabled': False,
                    'legacy_analyzer': 'deepseek',
                    'status': 'available' if hasattr(self, 'legacy_analyzer') else 'unavailable'
                }
            except Exception as e:
                return {
                    'multi_ai_enabled': False,
                    'legacy_analyzer': 'deepseek',
                    'status': 'error',
                    'error': str(e)
                }


# å·¥å‚å‡½æ•°ï¼Œç”¨äºåˆ›å»ºé€‚é…å™¨
def create_ai_analyzer(config) -> AIAnalyzerAdapter:
    """
    åˆ›å»ºAIåˆ†æå™¨é€‚é…å™¨
    
    Args:
        config: é…ç½®å¯¹è±¡
    
    Returns:
        AIåˆ†æå™¨é€‚é…å™¨å®ä¾‹
    """
    return AIAnalyzerAdapter(config) 