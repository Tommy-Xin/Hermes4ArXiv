#!/usr/bin/env python3
"""
AI åˆ†æå™¨æ¨¡å—
ä½¿ç”¨ DeepSeek API è¿›è¡Œæ‰€æœ‰åˆ†æã€‚
"""

import logging
import time
import json
from typing import Dict, Any, List

import openai
from tenacity import retry, stop_after_attempt, wait_exponential

from ..config import Config
from .prompts import PromptManager

logger = logging.getLogger(__name__)


class DeepSeekAnalyzer:
    """
    ä½¿ç”¨ DeepSeek API è¿›è¡Œè®ºæ–‡åˆ†æçš„ä¸»åˆ†æå™¨ã€‚
    æ”¯æŒå®Œæ•´çš„ä¸¤é˜¶æ®µåˆ†ææµç¨‹ã€‚
    """

    def __init__(self, config: Config):
        """
        åˆå§‹åŒ–åˆ†æå™¨ï¼Œä»é…ç½®ä¸­åŠ è½½è®¾ç½®ã€‚
        """
        self.config = config
        self.timeout = config.API_TIMEOUT
        self.model = config.DEEPSEEK_MODEL
        
        if not config.DEEPSEEK_API_KEY:
            raise ValueError("DEEPSEEK_API_KEY not found in config.")

        self.client = openai.OpenAI(
            api_key=config.DEEPSEEK_API_KEY,
            base_url="https://api.deepseek.com/v1"
        )

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def rank_papers_in_batch(self, papers: list[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å¯¹ä¸€å°æ‰¹è®ºæ–‡è¿›è¡Œå¼ºåˆ¶æ’åå’Œè¯„åˆ† (Stage 1).
        è¿”å›ä¸€ä¸ªåŒ…å«è¯„åˆ†ç»“æœçš„åˆ—è¡¨ã€‚
        """
        logger.info(f"Executing Stage 1: Ranking a batch of {len(papers)} papers using DeepSeek.")
        if not papers:
            return []

        response_text = ""
        try:
            system_prompt = PromptManager.get_stage1_ranking_system_prompt()
            user_prompt = PromptManager.format_stage1_ranking_prompt(papers)
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
                max_tokens=2048,
                temperature=0.2,
                response_format={"type": "json_object"},
                timeout=self.timeout
            )
            
            response_text = response.choices[0].message.content
            logger.debug(f"Raw Stage 1 ranking response from AI: {response_text}")
            
            parsed_json = json.loads(response_text)
            
            if isinstance(parsed_json, dict):
                ranking_list = next((v for v in parsed_json.values() if isinstance(v, list)), None)
                if ranking_list is None:
                    logger.error("AI returned a JSON object for ranking, but no list was found inside.")
                    return []
            elif isinstance(parsed_json, list):
                ranking_list = parsed_json
            else:
                logger.error(f"AI ranking response was not a JSON list or a dict containing a list. Type: {type(parsed_json)}")
                return []

            if not all('paper_id' in item and 'score' in item for item in ranking_list):
                logger.error("AI ranking response list has malformed items.")
                return []
                
            return ranking_list

        except json.JSONDecodeError as e:
            logger.error(f"Failed to decode JSON from AI ranking response: {e}\nProblematic text: {response_text}")
            return []
        except Exception as e:
            logger.error(f"An unexpected error occurred during paper ranking: {e}", exc_info=True)
            return []

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def analyze_papers_batch(self, papers: list[Dict[str, Any]]) -> str:
        """
        å¯¹ä¸€æ‰¹è®ºæ–‡è¿›è¡Œæ·±å…¥çš„æ‰¹é‡åˆ†æ (Stage 2).
        è¿”å›ä¸€ä¸ªåŒ…å«æ‰€æœ‰åˆ†æçš„é•¿å­—ç¬¦ä¸²ã€‚
        """
        logger.info(f"Executing Stage 2: Performing deep analysis on a batch of {len(papers)} papers using DeepSeek.")
        if not papers:
            return ""

        system_prompt = PromptManager.get_system_prompt()
        user_prompt = PromptManager.format_batch_analysis_prompt(papers)

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            max_tokens=8000,
            temperature=0.5,
            stream=False,
            timeout=self.timeout * 2
        )
        analysis_text = response.choices[0].message.content
        logger.info(f"Successfully completed deep analysis for {len(papers)} papers.")
        return analysis_text

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    def analyze_paper(self, paper: Dict[str, Any]) -> str:
        """
        å¯¹å•ç¯‡è®ºæ–‡è¿›è¡Œæ·±å…¥åˆ†æ (ç”¨äºåå¤‡æˆ–å•æ¬¡è¿è¡Œ).
        è¿”å›åŒ…å«åˆ†æç»“æœçš„å­—ç¬¦ä¸²ã€‚
        """
        logger.info(f"Performing single paper analysis for: {paper.get('title', 'N/A')} using DeepSeek.")
        system_prompt = PromptManager.get_system_prompt()
        
        # ç›´æ¥ä»å­—å…¸æ„å»ºPromptï¼Œä»¥é€‚åº”æ•°æ®åº“è®°å½•çš„æ ¼å¼
        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ArXivè®ºæ–‡ï¼š
ğŸ“„ **è®ºæ–‡æ ‡é¢˜**ï¼š{paper.get('title', 'æœªçŸ¥æ ‡é¢˜')}
ğŸ‘¥ **ä½œè€…ä¿¡æ¯**ï¼š{paper.get('authors', 'æœªçŸ¥ä½œè€…')}
ğŸ·ï¸ **ç ”ç©¶é¢†åŸŸ**ï¼š{paper.get('categories', 'æœªçŸ¥é¢†åŸŸ')}
ğŸ“… **å‘å¸ƒæ—¶é—´**ï¼š{paper.get('published_date', 'æœªçŸ¥æ—¥æœŸ')}
ğŸ“ **è®ºæ–‡æ‘˜è¦**ï¼š{paper.get('abstract', 'æ‘˜è¦ä¸å¯ç”¨')}
ğŸ”— **è®ºæ–‡é“¾æ¥**ï¼šhttps://arxiv.org/abs/{paper.get('paper_id', '')}
---
è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼ŒæŒ‰ç…§ç³»ç»Ÿæç¤ºçš„ç»“æ„è¿›è¡Œæ·±åº¦åˆ†æã€‚"""
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            max_tokens=2000,
            temperature=0.7,
            timeout=self.timeout
        )
        
        return response.choices[0].message.content 