#!/usr/bin/env python3
"""
æ™ºèƒ½AIå›é€€ç³»ç»Ÿæ¨¡å—
æ”¯æŒå•AIä½¿ç”¨ + æ™ºèƒ½å›é€€ç­–ç•¥ï¼Œç¡®ä¿è®ºæ–‡åˆ†æçš„é«˜å¯é æ€§
"""

import asyncio
import logging
import time
from abc import ABC, abstractmethod
from enum import Enum
from typing import Dict, List, Optional, Tuple, Any
import arxiv
from collections import defaultdict

from .prompts import PromptManager

logger = logging.getLogger(__name__)


class AIProvider(Enum):
    """AIæä¾›å•†æšä¸¾"""
    DEEPSEEK = "deepseek"
    OPENAI = "openai"
    CLAUDE = "claude"
    GEMINI = "gemini"
    ZHIPU = "zhipu"  # æ™ºè°±AI


class FailureTracker:
    """å¤±è´¥è·Ÿè¸ªå™¨ - è·Ÿè¸ªAPIè¿ç»­å¤±è´¥æƒ…å†µ"""
    
    def __init__(self, max_consecutive_failures: int = 3, reset_time: int = 300):
        """
        åˆå§‹åŒ–å¤±è´¥è·Ÿè¸ªå™¨
        
        Args:
            max_consecutive_failures: æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•°
            reset_time: å¤±è´¥è®¡æ•°é‡ç½®æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.max_consecutive_failures = max_consecutive_failures
        self.reset_time = reset_time
        self.failure_counts = defaultdict(int)  # æ¯ä¸ªproviderçš„è¿ç»­å¤±è´¥æ¬¡æ•°
        self.last_failure_time = defaultdict(float)  # æœ€åå¤±è´¥æ—¶é—´
        self.disabled_providers = set()  # è¢«ç¦ç”¨çš„provider
    
    def record_failure(self, provider: AIProvider) -> bool:
        """
        è®°å½•å¤±è´¥
        
        Args:
            provider: AIæä¾›å•†
            
        Returns:
            æ˜¯å¦åº”è¯¥ç¦ç”¨è¯¥provider
        """
        current_time = time.time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®è®¡æ•°
        if (provider in self.last_failure_time and 
            current_time - self.last_failure_time[provider] > self.reset_time):
            self.failure_counts[provider] = 0
        
        self.failure_counts[provider] += 1
        self.last_failure_time[provider] = current_time
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å¤±è´¥æ¬¡æ•°
        if self.failure_counts[provider] >= self.max_consecutive_failures:
            self.disabled_providers.add(provider)
            logger.warning(f"ğŸš« {provider.value} è¿ç»­å¤±è´¥ {self.failure_counts[provider]} æ¬¡ï¼Œæš‚æ—¶ç¦ç”¨")
            return True
        
        return False
    
    def record_success(self, provider: AIProvider):
        """è®°å½•æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°"""
        self.failure_counts[provider] = 0
        if provider in self.disabled_providers:
            self.disabled_providers.remove(provider)
            logger.info(f"âœ… {provider.value} æ¢å¤æ­£å¸¸")
    
    def is_disabled(self, provider: AIProvider) -> bool:
        """æ£€æŸ¥provideræ˜¯å¦è¢«ç¦ç”¨"""
        return provider in self.disabled_providers
    
    def get_failure_info(self, provider: AIProvider) -> Dict[str, Any]:
        """è·å–å¤±è´¥ä¿¡æ¯"""
        return {
            'consecutive_failures': self.failure_counts.get(provider, 0),
            'is_disabled': self.is_disabled(provider),
            'last_failure_time': self.last_failure_time.get(provider, 0)
        }


class BaseAIAnalyzer(ABC):
    """AIåˆ†æå™¨åŸºç±»"""
    
    def __init__(self, api_key: str, model: str = None, **kwargs):
        self.api_key = api_key
        self.model = model
        self.is_available_flag = bool(api_key and len(api_key) > 10)
        self.retry_times = kwargs.get('retry_times', 3)
        self.delay = kwargs.get('delay', 2)
        self.timeout = kwargs.get('timeout', 30)
    
    @abstractmethod
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        pass
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨"""
        return self.is_available_flag
    
    @abstractmethod
    def get_provider_info(self) -> Dict[str, str]:
        """è·å–æä¾›å•†ä¿¡æ¯"""
        pass
    
    def _format_analysis_result(self, analysis_text: str, provider: str, model: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–åˆ†æç»“æœ"""
        return {
            'analysis': analysis_text,
            'provider': provider,
            'model': model,
            'timestamp': time.time(),
            'html_analysis': PromptManager.format_analysis_for_html(analysis_text)
        }


class DeepSeekAnalyzer(BaseAIAnalyzer):
    """DeepSeekåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "deepseek-chat", **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.base_url = "https://api.deepseek.com/v1"
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        import openai
        
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„OpenAIåº“
        try:
            # æ–°ç‰ˆæœ¬ OpenAI (>=1.0.0)
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            use_new_api = True
        except AttributeError:
            # è€ç‰ˆæœ¬ OpenAI (<1.0.0)
            openai.api_key = self.api_key
            openai.api_base = self.base_url
            use_new_api = False
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"DeepSeekåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                if use_new_api:
                    # æ–°ç‰ˆæœ¬API
                    response = client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=1500,
                        timeout=self.timeout
                    )
                    analysis = response.choices[0].message.content
                else:
                    # è€ç‰ˆæœ¬API
                    response = openai.ChatCompletion.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=1500,
                        request_timeout=self.timeout
                    )
                    analysis = response.choices[0].message.content
                logger.info(f"DeepSeekåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "deepseek", self.model)
                
            except Exception as e:
                logger.warning(f"DeepSeekåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "DeepSeek",
            "provider": "deepseek",
            "model": self.model,
            "description": "DeepSeek - é«˜æ€§ä»·æ¯”AIæ¨¡å‹"
        }


class OpenAIAnalyzer(BaseAIAnalyzer):
    """OpenAIåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo", **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.base_url = "https://api.openai.com/v1"
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        import openai
        
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„OpenAIåº“
        try:
            # æ–°ç‰ˆæœ¬ OpenAI (>=1.0.0)
            client = openai.OpenAI(api_key=self.api_key)
            use_new_api = True
        except AttributeError:
            # è€ç‰ˆæœ¬ OpenAI (<1.0.0)
            openai.api_key = self.api_key
            use_new_api = False
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"OpenAIåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                if use_new_api:
                    # æ–°ç‰ˆæœ¬API
                    response = client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=1500,
                        timeout=self.timeout
                    )
                    analysis = response.choices[0].message.content
                else:
                    # è€ç‰ˆæœ¬API
                    response = openai.ChatCompletion.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=1500,
                        request_timeout=self.timeout
                    )
                    analysis = response.choices[0].message.content
                logger.info(f"OpenAIåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "openai", self.model)
                
            except Exception as e:
                logger.warning(f"OpenAIåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "OpenAI",
            "provider": "openai",
            "model": self.model,
            "description": "OpenAI GPT - ä¸šç•Œé¢†å…ˆAIæ¨¡å‹"
        }


class ClaudeAnalyzer(BaseAIAnalyzer):
    """Claudeåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "claude-3-haiku-20240307", **kwargs):
        super().__init__(api_key, model, **kwargs)
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        try:
            import anthropic
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… anthropic åº“: pip install anthropic")
        
        client = anthropic.Anthropic(api_key=self.api_key)
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"Claudeåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                message = client.messages.create(
                    model=self.model,
                    max_tokens=1500,
                    temperature=0.7,
                    system=system_prompt,
                    messages=[{"role": "user", "content": user_prompt}]
                )
                
                analysis = message.content[0].text
                logger.info(f"Claudeåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "claude", self.model)
                
            except Exception as e:
                logger.warning(f"Claudeåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "Claude",
            "provider": "claude",
            "model": self.model,
            "description": "Anthropic Claude - å®‰å…¨å¯é AIåŠ©æ‰‹"
        }


class GeminiAnalyzer(BaseAIAnalyzer):
    """Geminiåˆ†æå™¨ - ä½¿ç”¨å¢å¼ºç‰ˆä¿®å¤å™¨ï¼Œè§£å†³å®‰å…¨è¿‡æ»¤å™¨é—®é¢˜"""
    
    def __init__(self, api_key: str, model: str = "gemini-2.5-pro-preview-05-06", **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.fixer = None
        self._initialize_fixer()
    
    def _initialize_fixer(self):
        """åˆå§‹åŒ–Geminiä¿®å¤å™¨"""
        try:
            # å¯¼å…¥æˆ‘ä»¬çš„ä¿®å¤å™¨
            from ai.gemini_fix import GeminiAPIFixer
            
            self.fixer = GeminiAPIFixer(
                api_key=self.api_key,
                model=self.model,
                retry_times=self.retry_times,
                delay=self.delay
            )
            logger.info(f"âœ… Geminiä¿®å¤å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model}")
        except Exception as e:
            logger.error(f"âŒ Geminiä¿®å¤å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.fixer = None
            self.is_available_flag = False
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        if not self.fixer:
            raise Exception("Geminiä¿®å¤å™¨æœªåˆå§‹åŒ–")
        
        try:
            logger.info(f"Geminiä¿®å¤å™¨åˆ†æè®ºæ–‡: {paper.title[:50]}...")
            
            # ä½¿ç”¨æˆ‘ä»¬çš„ä¿®å¤å™¨è¿›è¡Œåˆ†æ
            result = await self.fixer.analyze_paper(paper, analysis_type)
            
            if result:
                logger.info(f"âœ… Geminiä¿®å¤å™¨åˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                # ç¡®ä¿è¿”å›æ­£ç¡®çš„æ ¼å¼
                return {
                    'analysis': result['analysis'],
                    'provider': 'gemini',
                    'model': result['model'],
                    'timestamp': result['timestamp'],
                    'html_analysis': PromptManager.format_analysis_for_html(result['analysis']),
                    'api_version': result.get('api_version', 'unknown'),
                    'analysis_type': result.get('analysis_type', analysis_type)
                }
            else:
                raise Exception("Geminiä¿®å¤å™¨è¿”å›ç©ºç»“æœï¼Œå¯èƒ½æ˜¯åœ°ç†ä½ç½®é™åˆ¶æˆ–å…¶ä»–é—®é¢˜")
                
        except Exception as e:
            logger.error(f"âŒ Geminiä¿®å¤å™¨åˆ†æå¤±è´¥: {str(e)}")
            # æ£€æŸ¥æ˜¯å¦æ˜¯åœ°ç†ä½ç½®é™åˆ¶
            if "location is not supported" in str(e).lower():
                logger.error("ğŸŒ Gemini APIåœ°ç†ä½ç½®é™åˆ¶ - åœ¨GitHub Actionsä¸­ä¸åº”å‡ºç°æ­¤é”™è¯¯")
            raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "Gemini Enhanced",
            "provider": "gemini",
            "model": self.model,
            "description": "Google Gemini with Enhanced Safety Filter Fix",
            "api_version": getattr(self.fixer, 'api_version', 'unknown') if self.fixer else 'unavailable'
        }


class MultiAIAnalyzer:
    """
    æ™ºèƒ½AIå›é€€ç³»ç»Ÿ - ä¸»AI + å¤‡ç”¨AIé™çº§ç­–ç•¥
    
    å·¥ä½œåŸç†ï¼š
    1. ä¼˜å…ˆä½¿ç”¨æ‚¨é…ç½®çš„ä¸»è¦AIï¼ˆå¦‚Gemini 2.5 Pro Previewï¼‰
    2. å½“ä¸»AIå¤±è´¥æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨AIï¼ˆå¦‚DeepSeekï¼‰
    3. æ¯ç¯‡è®ºæ–‡åªä½¿ç”¨ä¸€ä¸ªAIåˆ†æï¼Œç¡®ä¿æˆæœ¬å¯æ§
    4. æ”¯æŒæ™ºèƒ½å¤±è´¥æ£€æµ‹å’Œä¸´æ—¶ç¦ç”¨æœºåˆ¶
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.analyzers: Dict[AIProvider, BaseAIAnalyzer] = {}
        self.fallback_order = self._parse_fallback_order()
        self.failure_tracker = FailureTracker(
            max_consecutive_failures=config.get('MAX_CONSECUTIVE_FAILURES', 3),
            reset_time=config.get('FAILURE_RESET_TIME', 300)
        )
        self._initialize_analyzers()
    
    def _parse_fallback_order(self) -> List[AIProvider]:
        """è§£æä½¿ç”¨é¡ºåº - æ”¯æŒç”¨æˆ·æŒ‡å®šä¼˜å…ˆæ¨¡å‹"""
        
        # ğŸ¯ ä¼˜å…ˆæ£€æŸ¥ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹
        preferred_model = self.config.get('PREFERRED_AI_MODEL', '').lower().strip()
        if preferred_model:
            try:
                preferred_provider = AIProvider(preferred_model)
                # æ£€æŸ¥è¯¥æ¨¡å‹æ˜¯å¦å¯ç”¨
                if self.config.get(f'{preferred_model.upper()}_API_KEY'):
                    logger.info(f"ğŸ¯ ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„AIæ¨¡å‹: {preferred_model}")
                    return [preferred_provider]  # åªä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹
                else:
                    logger.warning(f"âš ï¸ ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ {preferred_model} æ²¡æœ‰é…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨è‡ªåŠ¨é€‰æ‹©")
            except ValueError:
                logger.warning(f"âš ï¸ ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ {preferred_model} ä¸æ”¯æŒï¼Œä½¿ç”¨è‡ªåŠ¨é€‰æ‹©")
        
        # SOTAæ¨¡å‹ä¼˜å…ˆçº§é¡ºåºï¼ˆ2025å¹´5æœˆæœ€æ–°ï¼‰
        sota_priority = ['claude', 'gemini', 'openai', 'deepseek']
        
        # æ£€æŸ¥ç”¨æˆ·é…ç½®çš„APIå¯†é’¥ï¼ŒæŒ‰SOTAä¼˜å…ˆçº§æ’åº
        available_providers = []
        for provider_name in sota_priority:
            if self.config.get(f'{provider_name.upper()}_API_KEY'):
                try:
                    provider = AIProvider(provider_name)
                    available_providers.append(provider)
                except ValueError:
                    logger.warning(f"æœªçŸ¥çš„AIæä¾›å•†: {provider_name}")
        
        # å¦‚æœç”¨æˆ·æ˜ç¡®è®¾ç½®äº†é™çº§é¡ºåºï¼Œå°Šé‡ç”¨æˆ·è®¾ç½®
        if self.config.get('AI_FALLBACK_ORDER'):
            order_str = self.config.get('AI_FALLBACK_ORDER')
            user_order = []
            for provider_name in order_str.split(','):
                provider_name = provider_name.strip().lower()
                try:
                    provider = AIProvider(provider_name)
                    if provider in available_providers:
                        user_order.append(provider)
                except ValueError:
                    logger.warning(f"æœªçŸ¥çš„AIæä¾›å•†: {provider_name}")
            if user_order:
                return user_order
        
        # è¿”å›å¯ç”¨çš„æä¾›å•†ï¼ˆæŒ‰SOTAä¼˜å…ˆçº§ï¼‰
        return available_providers if available_providers else [AIProvider.DEEPSEEK]
    
    def _initialize_analyzers(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        # DeepSeek
        if self.config.get('DEEPSEEK_API_KEY'):
            self.analyzers[AIProvider.DEEPSEEK] = DeepSeekAnalyzer(
                api_key=self.config['DEEPSEEK_API_KEY'],
                model=self.config.get('DEEPSEEK_MODEL', 'deepseek-chat'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # OpenAI - é»˜è®¤ä½¿ç”¨o3ï¼ˆ2025å¹´SOTAæ¨ç†æ¨¡å‹ï¼‰
        if self.config.get('OPENAI_API_KEY'):
            self.analyzers[AIProvider.OPENAI] = OpenAIAnalyzer(
                api_key=self.config['OPENAI_API_KEY'],
                model=self.config.get('OPENAI_MODEL', 'o3-2025-04-16'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # Claude - é»˜è®¤ä½¿ç”¨Claude Opus 4ï¼ˆ2025å¹´æœ€å¼ºæ¨¡å‹ï¼‰
        if self.config.get('CLAUDE_API_KEY'):
            self.analyzers[AIProvider.CLAUDE] = ClaudeAnalyzer(
                api_key=self.config['CLAUDE_API_KEY'],
                model=self.config.get('CLAUDE_MODEL', 'claude-opus-4-20250514'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # Gemini - é»˜è®¤ä½¿ç”¨Gemini 2.5 Pro Previewï¼ˆ2025å¹´æœ€æ–°SOTAï¼‰
        if self.config.get('GEMINI_API_KEY'):
            self.analyzers[AIProvider.GEMINI] = GeminiAnalyzer(
                api_key=self.config['GEMINI_API_KEY'],
                model=self.config.get('GEMINI_MODEL', 'gemini-2.5-pro-preview-05-06'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        logger.info(f"åˆå§‹åŒ–äº† {len(self.analyzers)} ä¸ªAIåˆ†æå™¨: {list(self.analyzers.keys())}")
    
    def get_available_analyzers(self) -> List[AIProvider]:
        """è·å–å¯ç”¨çš„åˆ†æå™¨åˆ—è¡¨ï¼ˆæ’é™¤è¢«ç¦ç”¨çš„ï¼‰"""
        return [
            provider for provider, analyzer in self.analyzers.items() 
            if analyzer.is_available() and not self.failure_tracker.is_disabled(provider)
        ]
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """
        åˆ†æè®ºæ–‡ - ä½¿ç”¨é™çº§ç­–ç•¥
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
            analysis_type: åˆ†æç±»å‹
        
        Returns:
            åˆ†æç»“æœ
        """
        return await self._analyze_with_fallback(paper, analysis_type)
    
    async def _analyze_with_fallback(self, paper: arxiv.Result, analysis_type: str) -> Dict[str, Any]:
        """ä½¿ç”¨é™çº§ç­–ç•¥åˆ†æè®ºæ–‡ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒæ™ºèƒ½è·³è¿‡å¤±è´¥çš„AI"""
        last_error = None
        attempted_providers = []
        
        # è·å–å¯ç”¨çš„provideråˆ—è¡¨ï¼ˆæ’é™¤è¢«ç¦ç”¨çš„ï¼‰
        available_providers = [
            provider for provider in self.fallback_order
            if (provider in self.analyzers and 
                self.analyzers[provider].is_available() and
                not self.failure_tracker.is_disabled(provider))
        ]
        
        if not available_providers:
            # æ‰€æœ‰provideréƒ½è¢«ç¦ç”¨ï¼Œå°è¯•é‡ç½®ä¸€äº›å¤±è´¥è®¡æ•°
            logger.warning("æ‰€æœ‰AIæä¾›å•†éƒ½è¢«ç¦ç”¨ï¼Œå°è¯•é‡ç½®éƒ¨åˆ†å¤±è´¥è®¡æ•°")
            self._reset_some_failures()
            available_providers = [
                provider for provider in self.fallback_order
                if (provider in self.analyzers and 
                    self.analyzers[provider].is_available() and
                    not self.failure_tracker.is_disabled(provider))
            ]
        
        for provider in available_providers:
            analyzer = self.analyzers.get(provider)
            attempted_providers.append(provider)
            
            try:
                logger.info(f"ä½¿ç”¨ {provider.value} åˆ†æè®ºæ–‡: {paper.title[:50]}...")
                result = await analyzer.analyze_paper(paper, analysis_type)
                
                # è®°å½•æˆåŠŸ
                self.failure_tracker.record_success(provider)
                logger.info(f"âœ… {provider.value} åˆ†ææˆåŠŸ")
                return result
                
            except Exception as e:
                last_error = e
                error_msg = str(e)
                
                # è®°å½•å¤±è´¥
                should_disable = self.failure_tracker.record_failure(provider)
                
                # ç‰¹æ®Šå¤„ç†Geminiå®‰å…¨è¿‡æ»¤å™¨é—®é¢˜
                if provider == AIProvider.GEMINI and "GEMINI_SAFETY_FILTER_REPEATEDLY_TRIGGERED" in error_msg:
                    logger.error(f"âŒ {provider.value} å¤šæ¬¡è§¦å‘å®‰å…¨è¿‡æ»¤å™¨ï¼Œå»ºè®®ä½¿ç”¨å…¶ä»–AIæ¨¡å‹")
                elif should_disable:
                    logger.warning(f"âš ï¸ {provider.value} è¢«æš‚æ—¶ç¦ç”¨ï¼Œå°†å°è¯•å…¶ä»–AI")
                else:
                    logger.warning(f"âŒ {provider.value} åˆ†æå¤±è´¥: {error_msg[:100]}...")
                
                continue
        
        # æ‰€æœ‰åˆ†æå™¨éƒ½å¤±è´¥äº†ï¼Œè¿”å›Noneè¡¨ç¤ºå®Œå…¨å¤±è´¥
        error_msg = f"æ‰€æœ‰å¯ç”¨çš„AIæä¾›å•†éƒ½å¤±è´¥äº†ã€‚å°è¯•è¿‡çš„æä¾›å•†: {[p.value for p in attempted_providers]}ã€‚æœ€åé”™è¯¯: {last_error}"
        logger.error(error_msg)
        
        # ç”Ÿæˆå¤±è´¥ç»Ÿè®¡ç”¨äºæ—¥å¿—è®°å½•
        failure_stats = self._get_failure_stats()
        logger.info(f"å¤±è´¥ç»Ÿè®¡: {failure_stats}")
        
        # è¿”å›Noneè¡¨ç¤ºå½»åº•å¤±è´¥ï¼Œéœ€è¦å‘é€é‚®ä»¶é€šçŸ¥
        return None
    
    def _reset_some_failures(self):
        """é‡ç½®ä¸€äº›å¤±è´¥è®¡æ•°ï¼Œç»™AIä¸€æ¬¡é‡æ–°å°è¯•çš„æœºä¼š"""
        for provider in self.failure_tracker.disabled_providers.copy():
            if provider != AIProvider.GEMINI:  # Geminiå®‰å…¨è¿‡æ»¤å™¨é—®é¢˜é€šå¸¸æ˜¯æŒç»­æ€§çš„
                self.failure_tracker.failure_counts[provider] = max(0, self.failure_tracker.failure_counts[provider] - 1)
                if self.failure_tracker.failure_counts[provider] < self.failure_tracker.max_consecutive_failures:
                    self.failure_tracker.disabled_providers.remove(provider)
                    logger.info(f"ğŸ”„ é‡ç½® {provider.value} å¤±è´¥è®¡æ•°ï¼Œç»™äºˆé‡è¯•æœºä¼š")
    
    def _get_failure_stats(self) -> Dict[str, Any]:
        """è·å–å¤±è´¥ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        for provider in self.analyzers.keys():
            stats[provider.value] = self.failure_tracker.get_failure_info(provider)
        return stats
    
    def get_analyzer_status(self) -> Dict[str, Any]:
        """è·å–åˆ†æå™¨çŠ¶æ€"""
        status = {
            'strategy': 'fallback',  # ç®€åŒ–ï¼šåªä½¿ç”¨fallbackç­–ç•¥
            'fallback_order': [p.value for p in self.fallback_order],
            'analyzers': {},
            'failure_stats': self._get_failure_stats()
        }
        
        for provider, analyzer in self.analyzers.items():
            info = analyzer.get_provider_info()
            info['available'] = analyzer.is_available()
            info['disabled'] = self.failure_tracker.is_disabled(provider)
            info['failure_info'] = self.failure_tracker.get_failure_info(provider)
            status['analyzers'][provider.value] = info
        
        return status 