#!/usr/bin/env python3
"""
å¤šAIåˆ†æå™¨æ¨¡å—
æ”¯æŒå¤šä¸ªAIæä¾›å•†çš„é™çº§ç­–ç•¥å’Œå¤±è´¥æ£€æµ‹
"""

import asyncio
import logging
import time
from abc import ABC, abstractmethod
from enum import Enum
from typing import Dict, List, Optional, Tuple, Any
import arxiv
from collections import defaultdict

from .prompts import PromptManager

logger = logging.getLogger(__name__)


class AIProvider(Enum):
    """AIæä¾›å•†æšä¸¾"""
    DEEPSEEK = "deepseek"
    OPENAI = "openai"
    CLAUDE = "claude"
    GEMINI = "gemini"
    ZHIPU = "zhipu"  # æ™ºè°±AI


class FailureTracker:
    """å¤±è´¥è·Ÿè¸ªå™¨ - è·Ÿè¸ªAPIè¿ç»­å¤±è´¥æƒ…å†µ"""
    
    def __init__(self, max_consecutive_failures: int = 3, reset_time: int = 300):
        """
        åˆå§‹åŒ–å¤±è´¥è·Ÿè¸ªå™¨
        
        Args:
            max_consecutive_failures: æœ€å¤§è¿ç»­å¤±è´¥æ¬¡æ•°
            reset_time: å¤±è´¥è®¡æ•°é‡ç½®æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.max_consecutive_failures = max_consecutive_failures
        self.reset_time = reset_time
        self.failure_counts = defaultdict(int)  # æ¯ä¸ªproviderçš„è¿ç»­å¤±è´¥æ¬¡æ•°
        self.last_failure_time = defaultdict(float)  # æœ€åå¤±è´¥æ—¶é—´
        self.disabled_providers = set()  # è¢«ç¦ç”¨çš„provider
    
    def record_failure(self, provider: AIProvider) -> bool:
        """
        è®°å½•å¤±è´¥
        
        Args:
            provider: AIæä¾›å•†
            
        Returns:
            æ˜¯å¦åº”è¯¥ç¦ç”¨è¯¥provider
        """
        current_time = time.time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®è®¡æ•°
        if (provider in self.last_failure_time and 
            current_time - self.last_failure_time[provider] > self.reset_time):
            self.failure_counts[provider] = 0
        
        self.failure_counts[provider] += 1
        self.last_failure_time[provider] = current_time
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§å¤±è´¥æ¬¡æ•°
        if self.failure_counts[provider] >= self.max_consecutive_failures:
            self.disabled_providers.add(provider)
            logger.warning(f"ğŸš« {provider.value} è¿ç»­å¤±è´¥ {self.failure_counts[provider]} æ¬¡ï¼Œæš‚æ—¶ç¦ç”¨")
            return True
        
        return False
    
    def record_success(self, provider: AIProvider):
        """è®°å½•æˆåŠŸï¼Œé‡ç½®å¤±è´¥è®¡æ•°"""
        self.failure_counts[provider] = 0
        if provider in self.disabled_providers:
            self.disabled_providers.remove(provider)
            logger.info(f"âœ… {provider.value} æ¢å¤æ­£å¸¸")
    
    def is_disabled(self, provider: AIProvider) -> bool:
        """æ£€æŸ¥provideræ˜¯å¦è¢«ç¦ç”¨"""
        return provider in self.disabled_providers
    
    def get_failure_info(self, provider: AIProvider) -> Dict[str, Any]:
        """è·å–å¤±è´¥ä¿¡æ¯"""
        return {
            'consecutive_failures': self.failure_counts.get(provider, 0),
            'is_disabled': self.is_disabled(provider),
            'last_failure_time': self.last_failure_time.get(provider, 0)
        }


class BaseAIAnalyzer(ABC):
    """AIåˆ†æå™¨åŸºç±»"""
    
    def __init__(self, api_key: str, model: str = None, **kwargs):
        self.api_key = api_key
        self.model = model
        self.is_available_flag = bool(api_key and len(api_key) > 10)
        self.retry_times = kwargs.get('retry_times', 3)
        self.delay = kwargs.get('delay', 2)
        self.timeout = kwargs.get('timeout', 30)
    
    @abstractmethod
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        pass
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨"""
        return self.is_available_flag
    
    @abstractmethod
    def get_provider_info(self) -> Dict[str, str]:
        """è·å–æä¾›å•†ä¿¡æ¯"""
        pass
    
    def _format_analysis_result(self, analysis_text: str, provider: str, model: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–åˆ†æç»“æœ"""
        return {
            'analysis': analysis_text,
            'provider': provider,
            'model': model,
            'timestamp': time.time(),
            'html_analysis': PromptManager.format_analysis_for_html(analysis_text)
        }


class DeepSeekAnalyzer(BaseAIAnalyzer):
    """DeepSeekåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "deepseek-r1", **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.base_url = "https://api.deepseek.com/v1"
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        import openai
        
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„OpenAIåº“
        try:
            # æ–°ç‰ˆæœ¬ OpenAI (>=1.0.0)
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
            use_new_api = True
        except AttributeError:
            # è€ç‰ˆæœ¬ OpenAI (<1.0.0)
            openai.api_key = self.api_key
            openai.api_base = self.base_url
            use_new_api = False
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"DeepSeekåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                if use_new_api:
                    # æ–°ç‰ˆæœ¬API
                    response = client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=1500,
                        timeout=self.timeout
                    )
                    analysis = response.choices[0].message.content
                else:
                    # è€ç‰ˆæœ¬API
                    response = openai.ChatCompletion.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=1500,
                        request_timeout=self.timeout
                    )
                    analysis = response.choices[0].message.content
                logger.info(f"DeepSeekåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "deepseek", self.model)
                
            except Exception as e:
                logger.warning(f"DeepSeekåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "DeepSeek",
            "provider": "deepseek",
            "model": self.model,
            "description": "DeepSeek - é«˜æ€§ä»·æ¯”AIæ¨¡å‹"
        }


class OpenAIAnalyzer(BaseAIAnalyzer):
    """OpenAIåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo", **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.base_url = "https://api.openai.com/v1"
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        import openai
        
        # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„OpenAIåº“
        try:
            # æ–°ç‰ˆæœ¬ OpenAI (>=1.0.0)
            client = openai.OpenAI(api_key=self.api_key)
            use_new_api = True
        except AttributeError:
            # è€ç‰ˆæœ¬ OpenAI (<1.0.0)
            openai.api_key = self.api_key
            use_new_api = False
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"OpenAIåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                if use_new_api:
                    # æ–°ç‰ˆæœ¬API
                    response = client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=1500,
                        timeout=self.timeout
                    )
                    analysis = response.choices[0].message.content
                else:
                    # è€ç‰ˆæœ¬API
                    response = openai.ChatCompletion.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        temperature=0.7,
                        max_tokens=1500,
                        request_timeout=self.timeout
                    )
                    analysis = response.choices[0].message.content
                logger.info(f"OpenAIåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "openai", self.model)
                
            except Exception as e:
                logger.warning(f"OpenAIåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "OpenAI",
            "provider": "openai",
            "model": self.model,
            "description": "OpenAI GPT - ä¸šç•Œé¢†å…ˆAIæ¨¡å‹"
        }


class ClaudeAnalyzer(BaseAIAnalyzer):
    """Claudeåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "claude-3-haiku-20240307", **kwargs):
        super().__init__(api_key, model, **kwargs)
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        try:
            import anthropic
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… anthropic åº“: pip install anthropic")
        
        client = anthropic.Anthropic(api_key=self.api_key)
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"Claudeåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                message = client.messages.create(
                    model=self.model,
                    max_tokens=1500,
                    temperature=0.7,
                    system=system_prompt,
                    messages=[{"role": "user", "content": user_prompt}]
                )
                
                analysis = message.content[0].text
                logger.info(f"Claudeåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "claude", self.model)
                
            except Exception as e:
                logger.warning(f"Claudeåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "Claude",
            "provider": "claude",
            "model": self.model,
            "description": "Anthropic Claude - å®‰å…¨å¯é AIåŠ©æ‰‹"
        }


class GeminiAnalyzer(BaseAIAnalyzer):
    """Geminiåˆ†æå™¨ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒfinish_reasonæ£€æµ‹"""
    
    # Gemini finish_reason æ˜ å°„
    FINISH_REASON_MAP = {
        0: "FINISH_REASON_UNSPECIFIED",
        1: "STOP",
        2: "SAFETY",
        3: "RECITATION", 
        4: "MAX_TOKENS",
        5: "OTHER"
    }
    
    def __init__(self, api_key: str, model: str = "gemini-pro", **kwargs):
        super().__init__(api_key, model, **kwargs)
        # é’ˆå¯¹å®‰å…¨è¿‡æ»¤å™¨çš„ç‰¹æ®Šå¤„ç†
        self.safety_failure_count = 0
        self.max_safety_failures = 2  # è¿ç»­2æ¬¡å®‰å…¨è¿‡æ»¤å¤±è´¥å°±è·³è¿‡
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        try:
            import google.generativeai as genai
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… google-generativeai åº“: pip install google-generativeai")
        
        genai.configure(api_key=self.api_key)
        model = genai.GenerativeModel(self.model)
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        # åˆå¹¶ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤º
        full_prompt = f"{system_prompt}\n\n{user_prompt}"
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"Geminiåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                # é…ç½®å®‰å…¨è®¾ç½® - é™ä½è¿‡æ»¤ä¸¥æ ¼ç¨‹åº¦
                safety_settings = [
                    {
                        "category": "HARM_CATEGORY_HARASSMENT",
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_HATE_SPEECH", 
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                        "threshold": "BLOCK_NONE"
                    },
                    {
                        "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                        "threshold": "BLOCK_NONE"
                    }
                ]
                
                response = model.generate_content(
                    full_prompt,
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=1500,
                        temperature=0.7,
                    ),
                    safety_settings=safety_settings
                )
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if not self._validate_response(response, paper.title):
                    continue  # ç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•
                
                analysis = response.text
                logger.info(f"Geminiåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                # é‡ç½®å®‰å…¨å¤±è´¥è®¡æ•°
                self.safety_failure_count = 0
                
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "gemini", self.model)
                
            except Exception as e:
                logger.warning(f"Geminiåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å®‰å…¨è¿‡æ»¤å™¨é—®é¢˜
                if self._is_safety_issue(str(e)):
                    self.safety_failure_count += 1
                    logger.warning(f"Geminiå®‰å…¨è¿‡æ»¤å™¨è§¦å‘ (è¿ç»­ {self.safety_failure_count} æ¬¡)")
                    
                    if self.safety_failure_count >= self.max_safety_failures:
                        logger.error(f"Geminiè¿ç»­ {self.safety_failure_count} æ¬¡è§¦å‘å®‰å…¨è¿‡æ»¤å™¨ï¼Œå»ºè®®åˆ‡æ¢åˆ°å…¶ä»–AI")
                        raise Exception("GEMINI_SAFETY_FILTER_REPEATEDLY_TRIGGERED")
                
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def _validate_response(self, response, paper_title: str) -> bool:
        """éªŒè¯Geminiå“åº”çŠ¶æ€"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å€™é€‰ç»“æœ
            if not response.candidates:
                logger.warning(f"Geminiå“åº”æ— å€™é€‰ç»“æœ: {paper_title[:50]}")
                return False
            
            candidate = response.candidates[0]
            finish_reason = candidate.finish_reason
            
            # è·å–finish_reasonçš„å¯è¯»åç§°
            reason_name = self.FINISH_REASON_MAP.get(finish_reason, f"UNKNOWN({finish_reason})")
            
            if finish_reason == 1:  # STOP - æ­£å¸¸å®Œæˆ
                return True
            elif finish_reason == 2:  # SAFETY - å®‰å…¨è¿‡æ»¤å™¨æ‹¦æˆª
                logger.warning(f"Geminiå®‰å…¨è¿‡æ»¤å™¨æ‹¦æˆª: {paper_title[:50]}, finish_reason: {reason_name}")
                self.safety_failure_count += 1
                return False
            elif finish_reason == 3:  # RECITATION - é‡å¤å†…å®¹æ£€æµ‹
                logger.warning(f"Geminié‡å¤å†…å®¹æ£€æµ‹: {paper_title[:50]}, finish_reason: {reason_name}")
                return False
            elif finish_reason == 4:  # MAX_TOKENS - è¾¾åˆ°æœ€å¤§tokenæ•°
                logger.warning(f"Geminiè¾¾åˆ°æœ€å¤§tokenæ•°: {paper_title[:50]}, finish_reason: {reason_name}")
                # è™½ç„¶æ²¡æœ‰å®Œæ•´è¾“å‡ºï¼Œä½†å¯èƒ½æœ‰éƒ¨åˆ†æœ‰ç”¨å†…å®¹
                if hasattr(response, 'text') and response.text:
                    return True
                return False
            else:
                logger.warning(f"GeminiæœªçŸ¥finish_reason: {reason_name}, è®ºæ–‡: {paper_title[:50]}")
                return False
                
        except Exception as e:
            logger.error(f"éªŒè¯Geminiå“åº”æ—¶å‡ºé”™: {e}")
            return False
    
    def _is_safety_issue(self, error_msg: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯å®‰å…¨è¿‡æ»¤å™¨ç›¸å…³é—®é¢˜"""
        safety_keywords = [
            "finish_reason",
            "safety",
            "blocked",
            "filter",
            "valid `Part`",
            "SAFETY"
        ]
        error_lower = error_msg.lower()
        return any(keyword.lower() in error_lower for keyword in safety_keywords)
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "Gemini",
            "provider": "gemini",
            "model": self.model,
            "description": "Google Gemini - å¤šæ¨¡æ€AIæ¨¡å‹",
            "safety_failure_count": self.safety_failure_count
        }


class MultiAIAnalyzer:
    """
    å¤šAIåˆ†æå™¨ - æ™ºèƒ½é™çº§åˆ†æå™¨
    
    ä½¿ç”¨é™çº§ç­–ç•¥ï¼ˆfallbackï¼‰æŒ‰é¡ºåºå°è¯•å¤šä¸ªAIæä¾›å•†ï¼Œ
    ç›´åˆ°æ‰¾åˆ°ä¸€ä¸ªå¯ç”¨çš„ä¸ºæ­¢ã€‚æ”¯æŒæ™ºèƒ½å¤±è´¥æ£€æµ‹å’Œè‡ªåŠ¨ç¦ç”¨ã€‚
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.analyzers: Dict[AIProvider, BaseAIAnalyzer] = {}
        self.fallback_order = self._parse_fallback_order()
        self.failure_tracker = FailureTracker(
            max_consecutive_failures=config.get('MAX_CONSECUTIVE_FAILURES', 3),
            reset_time=config.get('FAILURE_RESET_TIME', 300)
        )
        self._initialize_analyzers()
    
    def _parse_fallback_order(self) -> List[AIProvider]:
        """è§£æä½¿ç”¨é¡ºåº - æ”¯æŒç”¨æˆ·æŒ‡å®šä¼˜å…ˆæ¨¡å‹"""
        
        # ğŸ¯ ä¼˜å…ˆæ£€æŸ¥ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹
        preferred_model = self.config.get('PREFERRED_AI_MODEL', '').lower().strip()
        if preferred_model:
            try:
                preferred_provider = AIProvider(preferred_model)
                # æ£€æŸ¥è¯¥æ¨¡å‹æ˜¯å¦å¯ç”¨
                if self.config.get(f'{preferred_model.upper()}_API_KEY'):
                    logger.info(f"ğŸ¯ ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„AIæ¨¡å‹: {preferred_model}")
                    return [preferred_provider]  # åªä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹
                else:
                    logger.warning(f"âš ï¸ ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ {preferred_model} æ²¡æœ‰é…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨è‡ªåŠ¨é€‰æ‹©")
            except ValueError:
                logger.warning(f"âš ï¸ ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ {preferred_model} ä¸æ”¯æŒï¼Œä½¿ç”¨è‡ªåŠ¨é€‰æ‹©")
        
        # SOTAæ¨¡å‹ä¼˜å…ˆçº§é¡ºåºï¼ˆ2025å¹´5æœˆæœ€æ–°ï¼‰
        sota_priority = ['claude', 'gemini', 'openai', 'deepseek']
        
        # æ£€æŸ¥ç”¨æˆ·é…ç½®çš„APIå¯†é’¥ï¼ŒæŒ‰SOTAä¼˜å…ˆçº§æ’åº
        available_providers = []
        for provider_name in sota_priority:
            if self.config.get(f'{provider_name.upper()}_API_KEY'):
                try:
                    provider = AIProvider(provider_name)
                    available_providers.append(provider)
                except ValueError:
                    logger.warning(f"æœªçŸ¥çš„AIæä¾›å•†: {provider_name}")
        
        # å¦‚æœç”¨æˆ·æ˜ç¡®è®¾ç½®äº†é™çº§é¡ºåºï¼Œå°Šé‡ç”¨æˆ·è®¾ç½®
        if self.config.get('AI_FALLBACK_ORDER'):
            order_str = self.config.get('AI_FALLBACK_ORDER')
            user_order = []
            for provider_name in order_str.split(','):
                provider_name = provider_name.strip().lower()
                try:
                    provider = AIProvider(provider_name)
                    if provider in available_providers:
                        user_order.append(provider)
                except ValueError:
                    logger.warning(f"æœªçŸ¥çš„AIæä¾›å•†: {provider_name}")
            if user_order:
                return user_order
        
        # è¿”å›å¯ç”¨çš„æä¾›å•†ï¼ˆæŒ‰SOTAä¼˜å…ˆçº§ï¼‰
        return available_providers if available_providers else [AIProvider.DEEPSEEK]
    
    def _initialize_analyzers(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        # DeepSeek
        if self.config.get('DEEPSEEK_API_KEY'):
            self.analyzers[AIProvider.DEEPSEEK] = DeepSeekAnalyzer(
                api_key=self.config['DEEPSEEK_API_KEY'],
                model=self.config.get('DEEPSEEK_MODEL', 'deepseek-chat'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # OpenAI - é»˜è®¤ä½¿ç”¨o3ï¼ˆ2025å¹´SOTAæ¨ç†æ¨¡å‹ï¼‰
        if self.config.get('OPENAI_API_KEY'):
            self.analyzers[AIProvider.OPENAI] = OpenAIAnalyzer(
                api_key=self.config['OPENAI_API_KEY'],
                model=self.config.get('OPENAI_MODEL', 'o3-2025-04-16'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # Claude - é»˜è®¤ä½¿ç”¨Claude Opus 4ï¼ˆ2025å¹´æœ€å¼ºæ¨¡å‹ï¼‰
        if self.config.get('CLAUDE_API_KEY'):
            self.analyzers[AIProvider.CLAUDE] = ClaudeAnalyzer(
                api_key=self.config['CLAUDE_API_KEY'],
                model=self.config.get('CLAUDE_MODEL', 'claude-opus-4-20250514'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # Gemini - é»˜è®¤ä½¿ç”¨Gemini 2.5 Pro Previewï¼ˆ2025å¹´æœ€æ–°SOTAï¼‰
        if self.config.get('GEMINI_API_KEY'):
            self.analyzers[AIProvider.GEMINI] = GeminiAnalyzer(
                api_key=self.config['GEMINI_API_KEY'],
                model=self.config.get('GEMINI_MODEL', 'gemini-2.5-pro-preview-05-06'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        logger.info(f"åˆå§‹åŒ–äº† {len(self.analyzers)} ä¸ªAIåˆ†æå™¨: {list(self.analyzers.keys())}")
    
    def get_available_analyzers(self) -> List[AIProvider]:
        """è·å–å¯ç”¨çš„åˆ†æå™¨åˆ—è¡¨ï¼ˆæ’é™¤è¢«ç¦ç”¨çš„ï¼‰"""
        return [
            provider for provider, analyzer in self.analyzers.items() 
            if analyzer.is_available() and not self.failure_tracker.is_disabled(provider)
        ]
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """
        åˆ†æè®ºæ–‡ - ä½¿ç”¨é™çº§ç­–ç•¥
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
            analysis_type: åˆ†æç±»å‹
        
        Returns:
            åˆ†æç»“æœ
        """
        return await self._analyze_with_fallback(paper, analysis_type)
    
    async def _analyze_with_fallback(self, paper: arxiv.Result, analysis_type: str) -> Dict[str, Any]:
        """ä½¿ç”¨é™çº§ç­–ç•¥åˆ†æè®ºæ–‡ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒæ™ºèƒ½è·³è¿‡å¤±è´¥çš„AI"""
        last_error = None
        attempted_providers = []
        
        # è·å–å¯ç”¨çš„provideråˆ—è¡¨ï¼ˆæ’é™¤è¢«ç¦ç”¨çš„ï¼‰
        available_providers = [
            provider for provider in self.fallback_order
            if (provider in self.analyzers and 
                self.analyzers[provider].is_available() and
                not self.failure_tracker.is_disabled(provider))
        ]
        
        if not available_providers:
            # æ‰€æœ‰provideréƒ½è¢«ç¦ç”¨ï¼Œå°è¯•é‡ç½®ä¸€äº›å¤±è´¥è®¡æ•°
            logger.warning("æ‰€æœ‰AIæä¾›å•†éƒ½è¢«ç¦ç”¨ï¼Œå°è¯•é‡ç½®éƒ¨åˆ†å¤±è´¥è®¡æ•°")
            self._reset_some_failures()
            available_providers = [
                provider for provider in self.fallback_order
                if (provider in self.analyzers and 
                    self.analyzers[provider].is_available() and
                    not self.failure_tracker.is_disabled(provider))
            ]
        
        for provider in available_providers:
            analyzer = self.analyzers.get(provider)
            attempted_providers.append(provider)
            
            try:
                logger.info(f"ä½¿ç”¨ {provider.value} åˆ†æè®ºæ–‡: {paper.title[:50]}...")
                result = await analyzer.analyze_paper(paper, analysis_type)
                
                # è®°å½•æˆåŠŸ
                self.failure_tracker.record_success(provider)
                logger.info(f"âœ… {provider.value} åˆ†ææˆåŠŸ")
                return result
                
            except Exception as e:
                last_error = e
                error_msg = str(e)
                
                # è®°å½•å¤±è´¥
                should_disable = self.failure_tracker.record_failure(provider)
                
                # ç‰¹æ®Šå¤„ç†Geminiå®‰å…¨è¿‡æ»¤å™¨é—®é¢˜
                if provider == AIProvider.GEMINI and "GEMINI_SAFETY_FILTER_REPEATEDLY_TRIGGERED" in error_msg:
                    logger.error(f"âŒ {provider.value} å¤šæ¬¡è§¦å‘å®‰å…¨è¿‡æ»¤å™¨ï¼Œå»ºè®®ä½¿ç”¨å…¶ä»–AIæ¨¡å‹")
                elif should_disable:
                    logger.warning(f"âš ï¸ {provider.value} è¢«æš‚æ—¶ç¦ç”¨ï¼Œå°†å°è¯•å…¶ä»–AI")
                else:
                    logger.warning(f"âŒ {provider.value} åˆ†æå¤±è´¥: {error_msg[:100]}...")
                
                continue
        
        # æ‰€æœ‰åˆ†æå™¨éƒ½å¤±è´¥äº†
        error_msg = f"æ‰€æœ‰å¯ç”¨çš„AIæä¾›å•†éƒ½å¤±è´¥äº†ã€‚å°è¯•è¿‡çš„æä¾›å•†: {[p.value for p in attempted_providers]}ã€‚æœ€åé”™è¯¯: {last_error}"
        logger.error(error_msg)
        
        # ç”Ÿæˆå¤±è´¥ç»Ÿè®¡
        failure_stats = self._get_failure_stats()
        logger.info(f"å¤±è´¥ç»Ÿè®¡: {failure_stats}")
        
        return {
            'analysis': PromptManager.get_error_analysis(str(last_error)),
            'provider': 'error',
            'model': 'none',
            'timestamp': time.time(),
            'html_analysis': PromptManager.format_analysis_for_html(PromptManager.get_error_analysis(str(last_error))),
            'error': str(last_error),
            'attempted_providers': [p.value for p in attempted_providers],
            'failure_stats': failure_stats
        }
    
    def _reset_some_failures(self):
        """é‡ç½®ä¸€äº›å¤±è´¥è®¡æ•°ï¼Œç»™AIä¸€æ¬¡é‡æ–°å°è¯•çš„æœºä¼š"""
        for provider in self.failure_tracker.disabled_providers.copy():
            if provider != AIProvider.GEMINI:  # Geminiå®‰å…¨è¿‡æ»¤å™¨é—®é¢˜é€šå¸¸æ˜¯æŒç»­æ€§çš„
                self.failure_tracker.failure_counts[provider] = max(0, self.failure_tracker.failure_counts[provider] - 1)
                if self.failure_tracker.failure_counts[provider] < self.failure_tracker.max_consecutive_failures:
                    self.failure_tracker.disabled_providers.remove(provider)
                    logger.info(f"ğŸ”„ é‡ç½® {provider.value} å¤±è´¥è®¡æ•°ï¼Œç»™äºˆé‡è¯•æœºä¼š")
    
    def _get_failure_stats(self) -> Dict[str, Any]:
        """è·å–å¤±è´¥ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        for provider in self.analyzers.keys():
            stats[provider.value] = self.failure_tracker.get_failure_info(provider)
        return stats
    
    def get_analyzer_status(self) -> Dict[str, Any]:
        """è·å–åˆ†æå™¨çŠ¶æ€"""
        status = {
            'strategy': 'fallback',  # ç®€åŒ–ï¼šåªä½¿ç”¨fallbackç­–ç•¥
            'fallback_order': [p.value for p in self.fallback_order],
            'analyzers': {},
            'failure_stats': self._get_failure_stats()
        }
        
        for provider, analyzer in self.analyzers.items():
            info = analyzer.get_provider_info()
            info['available'] = analyzer.is_available()
            info['disabled'] = self.failure_tracker.is_disabled(provider)
            info['failure_info'] = self.failure_tracker.get_failure_info(provider)
            status['analyzers'][provider.value] = info
        
        return status 