#!/usr/bin/env python3
"""
å¤šAIåˆ†æå™¨æ¨¡å—
æ”¯æŒå¤šä¸ªAIæä¾›å•†çš„é™çº§ç­–ç•¥å’Œå¹¶è¡Œåˆ†æ
"""

import asyncio
import logging
import time
from abc import ABC, abstractmethod
from enum import Enum
from typing import Dict, List, Optional, Tuple, Any
import arxiv

from .prompts import PromptManager

logger = logging.getLogger(__name__)


class AIProvider(Enum):
    """AIæä¾›å•†æšä¸¾"""
    DEEPSEEK = "deepseek"
    OPENAI = "openai"
    CLAUDE = "claude"
    GEMINI = "gemini"
    ZHIPU = "zhipu"  # æ™ºè°±AI


class AnalysisStrategy(Enum):
    """åˆ†æç­–ç•¥æšä¸¾"""
    FALLBACK = "fallback"      # é™çº§ç­–ç•¥ï¼šæŒ‰é¡ºåºå°è¯•
    PARALLEL = "parallel"      # å¹¶è¡Œç­–ç•¥ï¼šåŒæ—¶è°ƒç”¨å¤šä¸ª
    CONSENSUS = "consensus"    # å…±è¯†ç­–ç•¥ï¼šå¤šä¸ªAIè¾¾æˆå…±è¯†
    BEST_EFFORT = "best_effort"  # å°½åŠ›è€Œä¸ºï¼šå°è¯•æ‰€æœ‰å¯ç”¨çš„


class BaseAIAnalyzer(ABC):
    """AIåˆ†æå™¨åŸºç±»"""
    
    def __init__(self, api_key: str, model: str = None, **kwargs):
        self.api_key = api_key
        self.model = model
        self.is_available_flag = bool(api_key and len(api_key) > 10)
        self.retry_times = kwargs.get('retry_times', 3)
        self.delay = kwargs.get('delay', 2)
        self.timeout = kwargs.get('timeout', 30)
    
    @abstractmethod
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        pass
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨"""
        return self.is_available_flag
    
    @abstractmethod
    def get_provider_info(self) -> Dict[str, str]:
        """è·å–æä¾›å•†ä¿¡æ¯"""
        pass
    
    def _format_analysis_result(self, analysis_text: str, provider: str, model: str) -> Dict[str, Any]:
        """æ ¼å¼åŒ–åˆ†æç»“æœ"""
        return {
            'analysis': analysis_text,
            'provider': provider,
            'model': model,
            'timestamp': time.time(),
            'html_analysis': PromptManager.format_analysis_for_html(analysis_text)
        }


class DeepSeekAnalyzer(BaseAIAnalyzer):
    """DeepSeekåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "deepseek-r1", **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.base_url = "https://api.deepseek.com/v1"
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        import openai
        
        # é…ç½®OpenAIå®¢æˆ·ç«¯ï¼ˆDeepSeekå…¼å®¹OpenAI APIï¼‰
        client = openai.OpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"DeepSeekåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                response = client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=1500,
                    timeout=self.timeout
                )
                
                analysis = response.choices[0].message.content
                logger.info(f"DeepSeekåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "deepseek", self.model)
                
            except Exception as e:
                logger.warning(f"DeepSeekåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "DeepSeek",
            "provider": "deepseek",
            "model": self.model,
            "description": "DeepSeek AI - é«˜æ€§ä»·æ¯”çš„ä¸­æ–‡AIæ¨¡å‹"
        }


class OpenAIAnalyzer(BaseAIAnalyzer):
    """OpenAIåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "gpt-3.5-turbo", **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.base_url = "https://api.openai.com/v1"
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        import openai
        
        client = openai.OpenAI(api_key=self.api_key)
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"OpenAIåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                response = client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.7,
                    max_tokens=1500,
                    timeout=self.timeout
                )
                
                analysis = response.choices[0].message.content
                logger.info(f"OpenAIåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "openai", self.model)
                
            except Exception as e:
                logger.warning(f"OpenAIåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "OpenAI",
            "provider": "openai",
            "model": self.model,
            "description": "OpenAI GPT - ä¸šç•Œé¢†å…ˆçš„AIæ¨¡å‹"
        }


class ClaudeAnalyzer(BaseAIAnalyzer):
    """Claudeåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "claude-3-haiku-20240307", **kwargs):
        super().__init__(api_key, model, **kwargs)
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        try:
            import anthropic
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… anthropic åº“: pip install anthropic")
        
        client = anthropic.Anthropic(api_key=self.api_key)
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"Claudeåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                response = client.messages.create(
                    model=self.model,
                    max_tokens=1500,
                    system=system_prompt,
                    messages=[
                        {"role": "user", "content": user_prompt}
                    ],
                    timeout=self.timeout
                )
                
                analysis = response.content[0].text
                logger.info(f"Claudeåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "claude", self.model)
                
            except Exception as e:
                logger.warning(f"Claudeåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "Claude",
            "provider": "claude",
            "model": self.model,
            "description": "Anthropic Claude - å®‰å…¨å¯é çš„AIåŠ©æ‰‹"
        }


class GeminiAnalyzer(BaseAIAnalyzer):
    """Geminiåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "gemini-pro", **kwargs):
        super().__init__(api_key, model, **kwargs)
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """åˆ†æè®ºæ–‡"""
        try:
            import google.generativeai as genai
        except ImportError:
            raise ImportError("éœ€è¦å®‰è£… google-generativeai åº“: pip install google-generativeai")
        
        genai.configure(api_key=self.api_key)
        model = genai.GenerativeModel(self.model)
        
        system_prompt = PromptManager.get_system_prompt(analysis_type)
        user_prompt = PromptManager.get_user_prompt(paper, analysis_type)
        
        # åˆå¹¶ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤º
        full_prompt = f"{system_prompt}\n\n{user_prompt}"
        
        for attempt in range(self.retry_times):
            try:
                logger.info(f"Geminiåˆ†æè®ºæ–‡: {paper.title[:50]}... (å°è¯• {attempt + 1}/{self.retry_times})")
                
                response = model.generate_content(
                    full_prompt,
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=1500,
                        temperature=0.7,
                    )
                )
                
                analysis = response.text
                logger.info(f"Geminiåˆ†æå®Œæˆ: {paper.title[:50]}...")
                
                await asyncio.sleep(self.delay)
                
                return self._format_analysis_result(analysis, "gemini", self.model)
                
            except Exception as e:
                logger.warning(f"Geminiåˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): {str(e)}")
                if attempt < self.retry_times - 1:
                    await asyncio.sleep(self.delay * (attempt + 1))
                else:
                    raise e
    
    def get_provider_info(self) -> Dict[str, str]:
        return {
            "name": "Gemini",
            "provider": "gemini",
            "model": self.model,
            "description": "Google Gemini - å¤šæ¨¡æ€AIæ¨¡å‹"
        }


class MultiAIAnalyzer:
    """å¤šAIåˆ†æå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.analyzers: Dict[AIProvider, BaseAIAnalyzer] = {}
        self.strategy = self._parse_strategy()
        self.fallback_order = self._parse_fallback_order()
        self._initialize_analyzers()
    
    def _parse_strategy(self) -> AnalysisStrategy:
        """è§£æåˆ†æç­–ç•¥"""
        strategy_str = self.config.get('ANALYSIS_STRATEGY', 'fallback').lower()
        try:
            return AnalysisStrategy(strategy_str)
        except ValueError:
            logger.warning(f"æœªçŸ¥çš„åˆ†æç­–ç•¥: {strategy_str}ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥: fallback")
            return AnalysisStrategy.FALLBACK
    
    def _parse_fallback_order(self) -> List[AIProvider]:
        """è§£æä½¿ç”¨é¡ºåº - æ”¯æŒç”¨æˆ·æŒ‡å®šä¼˜å…ˆæ¨¡å‹"""
        
        # ğŸ¯ ä¼˜å…ˆæ£€æŸ¥ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹
        preferred_model = self.config.get('PREFERRED_AI_MODEL', '').lower().strip()
        if preferred_model:
            try:
                preferred_provider = AIProvider(preferred_model)
                # æ£€æŸ¥è¯¥æ¨¡å‹æ˜¯å¦å¯ç”¨
                if self.config.get(f'{preferred_model.upper()}_API_KEY'):
                    logger.info(f"ğŸ¯ ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„AIæ¨¡å‹: {preferred_model}")
                    return [preferred_provider]  # åªä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹
                else:
                    logger.warning(f"âš ï¸ ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ {preferred_model} æ²¡æœ‰é…ç½®APIå¯†é’¥ï¼Œä½¿ç”¨è‡ªåŠ¨é€‰æ‹©")
            except ValueError:
                logger.warning(f"âš ï¸ ç”¨æˆ·æŒ‡å®šçš„æ¨¡å‹ {preferred_model} ä¸æ”¯æŒï¼Œä½¿ç”¨è‡ªåŠ¨é€‰æ‹©")
        
        # SOTAæ¨¡å‹ä¼˜å…ˆçº§é¡ºåºï¼ˆ2025å¹´5æœˆæœ€æ–°ï¼‰
        sota_priority = ['claude', 'gemini', 'openai', 'deepseek']
        
        # æ£€æŸ¥ç”¨æˆ·é…ç½®çš„APIå¯†é’¥ï¼ŒæŒ‰SOTAä¼˜å…ˆçº§æ’åº
        available_providers = []
        for provider_name in sota_priority:
            if self.config.get(f'{provider_name.upper()}_API_KEY'):
                try:
                    provider = AIProvider(provider_name)
                    available_providers.append(provider)
                except ValueError:
                    logger.warning(f"æœªçŸ¥çš„AIæä¾›å•†: {provider_name}")
        
        # å¦‚æœç”¨æˆ·æ˜ç¡®è®¾ç½®äº†é™çº§é¡ºåºï¼Œå°Šé‡ç”¨æˆ·è®¾ç½®
        if self.config.get('AI_FALLBACK_ORDER'):
            order_str = self.config.get('AI_FALLBACK_ORDER')
            user_order = []
            for provider_name in order_str.split(','):
                provider_name = provider_name.strip().lower()
                try:
                    provider = AIProvider(provider_name)
                    if provider in available_providers:
                        user_order.append(provider)
                except ValueError:
                    logger.warning(f"æœªçŸ¥çš„AIæä¾›å•†: {provider_name}")
            if user_order:
                return user_order
        
        # è¿”å›å¯ç”¨çš„æä¾›å•†ï¼ˆæŒ‰SOTAä¼˜å…ˆçº§ï¼‰
        return available_providers if available_providers else [AIProvider.DEEPSEEK]
    
    def _initialize_analyzers(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        # DeepSeek
        if self.config.get('DEEPSEEK_API_KEY'):
            self.analyzers[AIProvider.DEEPSEEK] = DeepSeekAnalyzer(
                api_key=self.config['DEEPSEEK_API_KEY'],
                model=self.config.get('DEEPSEEK_MODEL', 'deepseek-chat'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # OpenAI - é»˜è®¤ä½¿ç”¨o3ï¼ˆ2025å¹´SOTAæ¨ç†æ¨¡å‹ï¼‰
        if self.config.get('OPENAI_API_KEY'):
            self.analyzers[AIProvider.OPENAI] = OpenAIAnalyzer(
                api_key=self.config['OPENAI_API_KEY'],
                model=self.config.get('OPENAI_MODEL', 'o3-2025-04-16'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # Claude - é»˜è®¤ä½¿ç”¨Claude Opus 4ï¼ˆ2025å¹´æœ€å¼ºæ¨¡å‹ï¼‰
        if self.config.get('CLAUDE_API_KEY'):
            self.analyzers[AIProvider.CLAUDE] = ClaudeAnalyzer(
                api_key=self.config['CLAUDE_API_KEY'],
                model=self.config.get('CLAUDE_MODEL', 'claude-opus-4-20250514'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        # Gemini - é»˜è®¤ä½¿ç”¨Gemini 2.5 Pro Previewï¼ˆ2025å¹´æœ€æ–°SOTAï¼‰
        if self.config.get('GEMINI_API_KEY'):
            self.analyzers[AIProvider.GEMINI] = GeminiAnalyzer(
                api_key=self.config['GEMINI_API_KEY'],
                model=self.config.get('GEMINI_MODEL', 'gemini-2.5-pro-preview-05-06'),
                retry_times=self.config.get('API_RETRY_TIMES', 3),
                delay=self.config.get('API_DELAY', 2)
            )
        
        logger.info(f"åˆå§‹åŒ–äº† {len(self.analyzers)} ä¸ªAIåˆ†æå™¨: {list(self.analyzers.keys())}")
    
    def get_available_analyzers(self) -> List[AIProvider]:
        """è·å–å¯ç”¨çš„åˆ†æå™¨åˆ—è¡¨"""
        return [provider for provider, analyzer in self.analyzers.items() if analyzer.is_available()]
    
    async def analyze_paper(self, paper: arxiv.Result, analysis_type: str = "comprehensive") -> Dict[str, Any]:
        """
        åˆ†æè®ºæ–‡
        
        Args:
            paper: è®ºæ–‡å¯¹è±¡
            analysis_type: åˆ†æç±»å‹
        
        Returns:
            åˆ†æç»“æœ
        """
        if self.strategy == AnalysisStrategy.FALLBACK:
            return await self._analyze_with_fallback(paper, analysis_type)
        else:
            return await self._analyze_with_fallback(paper, analysis_type)
    
    async def _analyze_with_fallback(self, paper: arxiv.Result, analysis_type: str) -> Dict[str, Any]:
        """ä½¿ç”¨é™çº§ç­–ç•¥åˆ†æè®ºæ–‡"""
        last_error = None
        
        for provider in self.fallback_order:
            analyzer = self.analyzers.get(provider)
            if not analyzer or not analyzer.is_available():
                logger.debug(f"è·³è¿‡ä¸å¯ç”¨çš„åˆ†æå™¨: {provider}")
                continue
            
            try:
                logger.info(f"ä½¿ç”¨ {provider.value} åˆ†æè®ºæ–‡: {paper.title[:50]}...")
                result = await analyzer.analyze_paper(paper, analysis_type)
                logger.info(f"âœ… {provider.value} åˆ†ææˆåŠŸ")
                return result
                
            except Exception as e:
                last_error = e
                logger.warning(f"âŒ {provider.value} åˆ†æå¤±è´¥: {e}")
                continue
        
        # æ‰€æœ‰åˆ†æå™¨éƒ½å¤±è´¥äº†
        error_msg = f"æ‰€æœ‰AIæä¾›å•†éƒ½ä¸å¯ç”¨ã€‚æœ€åé”™è¯¯: {last_error}"
        logger.error(error_msg)
        
        return {
            'analysis': PromptManager.get_error_analysis(str(last_error)),
            'provider': 'error',
            'model': 'none',
            'timestamp': time.time(),
            'html_analysis': PromptManager.format_analysis_for_html(PromptManager.get_error_analysis(str(last_error))),
            'error': str(last_error)
        }
    
    def get_analyzer_status(self) -> Dict[str, Any]:
        """è·å–åˆ†æå™¨çŠ¶æ€"""
        status = {
            'strategy': self.strategy.value,
            'fallback_order': [p.value for p in self.fallback_order],
            'analyzers': {}
        }
        
        for provider, analyzer in self.analyzers.items():
            info = analyzer.get_provider_info()
            info['available'] = analyzer.is_available()
            status['analyzers'][provider.value] = info
        
        return status 