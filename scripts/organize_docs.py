#!/usr/bin/env python3
"""
æ–‡æ¡£æ•´ç†è„šæœ¬
å°†æ‰€æœ‰æ–‡æ¡£ç§»åŠ¨åˆ°docsæ–‡ä»¶å¤¹ï¼Œå¹¶è¯†åˆ«å’Œæ¸…ç†å†—ä½™æ–‡æ¡£
"""

import os
import shutil
from pathlib import Path
from typing import List, Dict, Set


class DocumentOrganizer:
    """æ–‡æ¡£æ•´ç†å™¨"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.docs_dir = project_root / "docs"
        
        # ç¡®ä¿docsç›®å½•å­˜åœ¨
        self.docs_dir.mkdir(exist_ok=True)
        
        # å®šä¹‰æ–‡æ¡£åˆ†ç±»
        self.doc_categories = {
            "setup": [
                "DEPLOY_FOR_USERS.md",
                "GMAIL_SETUP_GUIDE.md", 
                "QUICK_START_SUMMARY.md",
                "SECURITY.md"
            ],
            "development": [
                "TESTING_GUIDE.md",
                "PARALLEL_OPTIMIZATION_GUIDE.md",
                "PARALLEL_OPTIMIZATION_SUMMARY.md"
            ],
            "extensions": [
                "EXTENSIONS_SUMMARY.md",
                "QUICK_START_EXTENSIONS.md", 
                "EXTENSION_ROADMAP.md"
            ],
            "project": [
                "PROJECT_CLEANUP_SUMMARY.md",
                "PROJECT_COMPLETION_SUMMARY.md"
            ]
        }
        
        # éœ€è¦ä¿ç•™åœ¨æ ¹ç›®å½•çš„æ–‡æ¡£
        self.keep_in_root = {
            "README.md",
            "env.example",
            "Makefile",
            "pyproject.toml",
            "docker-compose.yml",
            "Dockerfile",
            ".pre-commit-config.yaml",
            ".gitignore"
        }

    def analyze_documents(self) -> Dict[str, List[str]]:
        """åˆ†æå½“å‰æ–‡æ¡£ç»“æ„"""
        print("ğŸ” åˆ†æå½“å‰æ–‡æ¡£ç»“æ„...")
        
        # è·å–æ‰€æœ‰markdownæ–‡ä»¶
        md_files = list(self.project_root.glob("*.md"))
        
        analysis = {
            "total_docs": len(md_files),
            "categorized": [],
            "uncategorized": [],
            "duplicates": [],
            "existing_in_docs": []
        }
        
        # æ£€æŸ¥docsç›®å½•ä¸­å·²æœ‰çš„æ–‡ä»¶
        existing_docs = list(self.docs_dir.glob("*.md"))
        analysis["existing_in_docs"] = [f.name for f in existing_docs]
        
        # åˆ†ç±»æ–‡æ¡£
        all_categorized = set()
        for category, files in self.doc_categories.items():
            all_categorized.update(files)
            
        for md_file in md_files:
            if md_file.name in self.keep_in_root:
                continue
                
            if md_file.name in all_categorized:
                analysis["categorized"].append(md_file.name)
            else:
                analysis["uncategorized"].append(md_file.name)
        
        # æ£€æŸ¥é‡å¤æ–‡æ¡£
        for doc in analysis["categorized"]:
            if doc in analysis["existing_in_docs"]:
                analysis["duplicates"].append(doc)
        
        return analysis

    def identify_redundant_docs(self) -> List[str]:
        """è¯†åˆ«å†—ä½™æ–‡æ¡£"""
        print("ğŸ” è¯†åˆ«å†—ä½™æ–‡æ¡£...")
        
        redundant_docs = []
        
        # æ£€æŸ¥å†…å®¹ç›¸ä¼¼çš„æ–‡æ¡£
        similar_pairs = [
            ("QUICK_START_SUMMARY.md", "DEPLOY_FOR_USERS.md"),
            ("EXTENSIONS_SUMMARY.md", "QUICK_START_EXTENSIONS.md"),
            ("PROJECT_CLEANUP_SUMMARY.md", "PROJECT_COMPLETION_SUMMARY.md"),
            ("PARALLEL_OPTIMIZATION_GUIDE.md", "PARALLEL_OPTIMIZATION_SUMMARY.md")
        ]
        
        for doc1, doc2 in similar_pairs:
            path1 = self.project_root / doc1
            path2 = self.project_root / doc2
            
            if path1.exists() and path2.exists():
                # ç®€å•çš„å†…å®¹é‡å¤æ£€æŸ¥
                content1 = path1.read_text(encoding='utf-8')
                content2 = path2.read_text(encoding='utf-8')
                
                # å¦‚æœä¸€ä¸ªæ–‡æ¡£çš„å†…å®¹åŒ…å«åœ¨å¦ä¸€ä¸ªä¸­ï¼Œæ ‡è®°ä¸ºå†—ä½™
                if len(content1) < len(content2) and content1[:200] in content2:
                    redundant_docs.append(doc1)
                elif len(content2) < len(content1) and content2[:200] in content1:
                    redundant_docs.append(doc2)
        
        return redundant_docs

    def create_docs_structure(self):
        """åˆ›å»ºdocsç›®å½•ç»“æ„"""
        print("ğŸ“ åˆ›å»ºdocsç›®å½•ç»“æ„...")
        
        # åˆ›å»ºå­ç›®å½•
        subdirs = ["setup", "development", "extensions", "project", "archive"]
        for subdir in subdirs:
            (self.docs_dir / subdir).mkdir(exist_ok=True)
            
        print(f"âœ… åˆ›å»ºäº†ä»¥ä¸‹å­ç›®å½•: {', '.join(subdirs)}")

    def move_documents(self, dry_run: bool = True):
        """ç§»åŠ¨æ–‡æ¡£åˆ°ç›¸åº”ç›®å½•"""
        print(f"ğŸ“¦ {'æ¨¡æ‹Ÿ' if dry_run else 'æ‰§è¡Œ'}æ–‡æ¡£ç§»åŠ¨...")
        
        moved_files = []
        
        for category, files in self.doc_categories.items():
            target_dir = self.docs_dir / category
            
            for filename in files:
                source_path = self.project_root / filename
                target_path = target_dir / filename
                
                if source_path.exists():
                    if dry_run:
                        print(f"  ğŸ“„ {filename} -> docs/{category}/")
                    else:
                        shutil.move(str(source_path), str(target_path))
                        print(f"  âœ… ç§»åŠ¨: {filename} -> docs/{category}/")
                    moved_files.append(filename)
        
        return moved_files

    def archive_redundant_docs(self, redundant_docs: List[str], dry_run: bool = True):
        """å½’æ¡£å†—ä½™æ–‡æ¡£"""
        if not redundant_docs:
            print("âœ… æ²¡æœ‰å‘ç°å†—ä½™æ–‡æ¡£")
            return
            
        print(f"ğŸ—„ï¸ {'æ¨¡æ‹Ÿ' if dry_run else 'æ‰§è¡Œ'}å†—ä½™æ–‡æ¡£å½’æ¡£...")
        
        archive_dir = self.docs_dir / "archive"
        
        for filename in redundant_docs:
            source_path = self.project_root / filename
            target_path = archive_dir / filename
            
            if source_path.exists():
                if dry_run:
                    print(f"  ğŸ“¦ {filename} -> docs/archive/")
                else:
                    shutil.move(str(source_path), str(target_path))
                    print(f"  âœ… å½’æ¡£: {filename} -> docs/archive/")

    def create_docs_index(self):
        """åˆ›å»ºæ–‡æ¡£ç´¢å¼•"""
        print("ğŸ“‹ åˆ›å»ºæ–‡æ¡£ç´¢å¼•...")
        
        index_content = """# æ–‡æ¡£ç´¢å¼•

æœ¬ç›®å½•åŒ…å«ArXivè®ºæ–‡è¿½è¸ªå™¨é¡¹ç›®çš„æ‰€æœ‰æ–‡æ¡£ã€‚

## ğŸ“ ç›®å½•ç»“æ„

### ğŸš€ setup/ - éƒ¨ç½²å’Œé…ç½®
- `DEPLOY_FOR_USERS.md` - å®Œæ•´éƒ¨ç½²æŒ‡å—
- `GMAIL_SETUP_GUIDE.md` - Gmailé…ç½®æŒ‡å—
- `QUICK_START_SUMMARY.md` - 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹
- `SECURITY.md` - å®‰å…¨ä¿éšœè¯´æ˜

### ğŸ”§ development/ - å¼€å‘å’Œä¼˜åŒ–
- `TESTING_GUIDE.md` - æµ‹è¯•æŒ‡å—
- `PARALLEL_OPTIMIZATION_GUIDE.md` - å¹¶è¡Œä¼˜åŒ–æŒ‡å—
- `PARALLEL_OPTIMIZATION_SUMMARY.md` - å¹¶è¡Œä¼˜åŒ–æ€»ç»“

### ğŸš€ extensions/ - æ‰©å±•åŠŸèƒ½
- `EXTENSIONS_SUMMARY.md` - æ‰©å±•åŠŸèƒ½æ€»ç»“
- `QUICK_START_EXTENSIONS.md` - æ‰©å±•åŠŸèƒ½å¿«é€Ÿå¼€å§‹
- `EXTENSION_ROADMAP.md` - æ‰©å±•åŠŸèƒ½è·¯çº¿å›¾

### ğŸ“Š project/ - é¡¹ç›®ç®¡ç†
- `PROJECT_CLEANUP_SUMMARY.md` - é¡¹ç›®æ¸…ç†æ€»ç»“
- `PROJECT_COMPLETION_SUMMARY.md` - é¡¹ç›®å®Œæˆæ€»ç»“

### ğŸ—„ï¸ archive/ - å½’æ¡£æ–‡æ¡£
å­˜æ”¾å·²è¿‡æ—¶æˆ–å†—ä½™çš„æ–‡æ¡£ã€‚

## ğŸ”— å¿«é€Ÿé“¾æ¥

- **æ–°ç”¨æˆ·**: ä» [å¿«é€Ÿå¼€å§‹](setup/QUICK_START_SUMMARY.md) å¼€å§‹
- **éƒ¨ç½²**: æŸ¥çœ‹ [éƒ¨ç½²æŒ‡å—](setup/DEPLOY_FOR_USERS.md)
- **Gmailé…ç½®**: å‚è€ƒ [Gmailè®¾ç½®](setup/GMAIL_SETUP_GUIDE.md)
- **æ€§èƒ½ä¼˜åŒ–**: é˜…è¯» [å¹¶è¡Œä¼˜åŒ–æŒ‡å—](development/PARALLEL_OPTIMIZATION_GUIDE.md)
- **æ‰©å±•åŠŸèƒ½**: æ¢ç´¢ [æ‰©å±•è·¯çº¿å›¾](extensions/EXTENSION_ROADMAP.md)

## ğŸ“ æ–‡æ¡£ç»´æŠ¤

æ–‡æ¡£æŒ‰åŠŸèƒ½åˆ†ç±»ç»„ç»‡ï¼Œä¾¿äºæŸ¥æ‰¾å’Œç»´æŠ¤ã€‚å¦‚éœ€æ·»åŠ æ–°æ–‡æ¡£ï¼Œè¯·æ”¾å…¥ç›¸åº”çš„åˆ†ç±»ç›®å½•ã€‚
"""
        
        index_path = self.docs_dir / "README.md"
        index_path.write_text(index_content, encoding='utf-8')
        print(f"âœ… åˆ›å»ºæ–‡æ¡£ç´¢å¼•: {index_path}")

    def update_root_readme(self):
        """æ›´æ–°æ ¹ç›®å½•READMEä¸­çš„æ–‡æ¡£é“¾æ¥"""
        print("ğŸ“ æ›´æ–°æ ¹ç›®å½•README...")
        
        readme_path = self.project_root / "README.md"
        if not readme_path.exists():
            print("âš ï¸ README.mdä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")
            return
            
        content = readme_path.read_text(encoding='utf-8')
        
        # æ›´æ–°æ–‡æ¡£é“¾æ¥
        replacements = {
            "DEPLOY_FOR_USERS.md": "docs/setup/DEPLOY_FOR_USERS.md",
            "GMAIL_SETUP_GUIDE.md": "docs/setup/GMAIL_SETUP_GUIDE.md", 
            "TESTING_GUIDE.md": "docs/development/TESTING_GUIDE.md",
            "PARALLEL_OPTIMIZATION_GUIDE.md": "docs/development/PARALLEL_OPTIMIZATION_GUIDE.md",
            "SECURITY.md": "docs/setup/SECURITY.md",
            "QUICK_START_SUMMARY.md": "docs/setup/QUICK_START_SUMMARY.md"
        }
        
        for old_link, new_link in replacements.items():
            content = content.replace(f"]({old_link})", f"]({new_link})")
            content = content.replace(f"](/{old_link})", f"]({new_link})")
        
        readme_path.write_text(content, encoding='utf-8')
        print("âœ… æ›´æ–°äº†READMEä¸­çš„æ–‡æ¡£é“¾æ¥")

    def run_organization(self, dry_run: bool = True):
        """è¿è¡Œå®Œæ•´çš„æ–‡æ¡£æ•´ç†æµç¨‹"""
        print("ğŸš€ å¼€å§‹æ–‡æ¡£æ•´ç†æµç¨‹")
        print("=" * 50)
        
        # 1. åˆ†æå½“å‰æ–‡æ¡£
        analysis = self.analyze_documents()
        print(f"ğŸ“Š æ–‡æ¡£åˆ†æç»“æœ:")
        print(f"  - æ€»æ–‡æ¡£æ•°: {analysis['total_docs']}")
        print(f"  - å·²åˆ†ç±»: {len(analysis['categorized'])}")
        print(f"  - æœªåˆ†ç±»: {len(analysis['uncategorized'])}")
        print(f"  - docsä¸­å·²æœ‰: {len(analysis['existing_in_docs'])}")
        
        if analysis['uncategorized']:
            print(f"  - æœªåˆ†ç±»æ–‡æ¡£: {', '.join(analysis['uncategorized'])}")
        
        # 2. è¯†åˆ«å†—ä½™æ–‡æ¡£
        redundant_docs = self.identify_redundant_docs()
        if redundant_docs:
            print(f"ğŸ” å‘ç°å†—ä½™æ–‡æ¡£: {', '.join(redundant_docs)}")
        
        # 3. åˆ›å»ºç›®å½•ç»“æ„
        self.create_docs_structure()
        
        # 4. ç§»åŠ¨æ–‡æ¡£
        moved_files = self.move_documents(dry_run)
        
        # 5. å½’æ¡£å†—ä½™æ–‡æ¡£
        self.archive_redundant_docs(redundant_docs, dry_run)
        
        # 6. åˆ›å»ºç´¢å¼•
        if not dry_run:
            self.create_docs_index()
            self.update_root_readme()
        
        print("=" * 50)
        if dry_run:
            print("âœ… æ¨¡æ‹Ÿè¿è¡Œå®Œæˆï¼ä½¿ç”¨ --execute å‚æ•°æ‰§è¡Œå®é™…æ“ä½œ")
        else:
            print("âœ… æ–‡æ¡£æ•´ç†å®Œæˆï¼")
            print(f"ğŸ“ æ–‡æ¡£å·²æ•´ç†åˆ° docs/ ç›®å½•")
            print(f"ğŸ“‹ æŸ¥çœ‹ docs/README.md äº†è§£æ–°çš„æ–‡æ¡£ç»“æ„")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ•´ç†é¡¹ç›®æ–‡æ¡£")
    parser.add_argument("--execute", action="store_true", help="æ‰§è¡Œå®é™…æ“ä½œï¼ˆé»˜è®¤ä¸ºæ¨¡æ‹Ÿè¿è¡Œï¼‰")
    parser.add_argument("--project-root", type=Path, default=Path.cwd().parent, help="é¡¹ç›®æ ¹ç›®å½•")
    
    args = parser.parse_args()
    
    organizer = DocumentOrganizer(args.project_root)
    organizer.run_organization(dry_run=not args.execute)


if __name__ == "__main__":
    main() 