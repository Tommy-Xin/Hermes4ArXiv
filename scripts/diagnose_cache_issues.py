#!/usr/bin/env python3
"""
GitHub Actionsç¼“å­˜é—®é¢˜è¯Šæ–­è„šæœ¬
"""

import json
import os
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional


def check_github_status() -> Dict[str, str]:
    """æ£€æŸ¥GitHubæœåŠ¡çŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥GitHubæœåŠ¡çŠ¶æ€...")
    
    try:
        # å°è¯•è®¿é—®GitHub API
        result = subprocess.run(
            ["curl", "-s", "https://www.githubstatus.com/api/v2/status.json"],
            capture_output=True,
            text=True,
            timeout=10
        )
        
        if result.returncode == 0:
            try:
                status_data = json.loads(result.stdout)
                return {
                    "status": status_data.get("status", {}).get("indicator", "unknown"),
                    "description": status_data.get("status", {}).get("description", "æ— æ³•è·å–çŠ¶æ€")
                }
            except json.JSONDecodeError:
                return {"status": "unknown", "description": "APIå“åº”è§£æå¤±è´¥"}
        else:
            return {"status": "error", "description": "æ— æ³•è¿æ¥åˆ°GitHubçŠ¶æ€API"}
    
    except Exception as e:
        return {"status": "error", "description": f"æ£€æŸ¥å¤±è´¥: {str(e)}"}


def analyze_workflow_logs() -> Dict[str, any]:
    """åˆ†æå·¥ä½œæµæ—¥å¿—ä¸­çš„ç¼“å­˜é—®é¢˜"""
    print("ğŸ“‹ åˆ†æå·¥ä½œæµé…ç½®...")
    
    project_root = Path(__file__).parent.parent
    workflows_dir = project_root / ".github" / "workflows"
    
    analysis = {
        "workflows_found": [],
        "cache_configurations": [],
        "potential_issues": []
    }
    
    if not workflows_dir.exists():
        analysis["potential_issues"].append("æœªæ‰¾åˆ°.github/workflowsç›®å½•")
        return analysis
    
    # æ£€æŸ¥å·¥ä½œæµæ–‡ä»¶
    for workflow_file in workflows_dir.glob("*.yml"):
        analysis["workflows_found"].append(workflow_file.name)
        
        try:
            content = workflow_file.read_text(encoding='utf-8')
            
            # æ£€æŸ¥ç¼“å­˜é…ç½®
            if "actions/cache@" in content:
                analysis["cache_configurations"].append({
                    "file": workflow_file.name,
                    "has_cache": True,
                    "has_continue_on_error": "continue-on-error" in content,
                    "has_timeout": "timeout" in content
                })
            
            # æ£€æŸ¥æ½œåœ¨é—®é¢˜
            if "enable-cache: true" in content and "continue-on-error" not in content:
                analysis["potential_issues"].append(
                    f"{workflow_file.name}: uvç¼“å­˜å¯ç”¨ä½†æ— å®¹é”™å¤„ç†"
                )
            
            if "actions/cache@" in content and "continue-on-error" not in content:
                analysis["potential_issues"].append(
                    f"{workflow_file.name}: ä½¿ç”¨ç¼“å­˜ä½†æ— å®¹é”™å¤„ç†"
                )
                
        except Exception as e:
            analysis["potential_issues"].append(f"è¯»å–{workflow_file.name}å¤±è´¥: {str(e)}")
    
    return analysis


def get_cache_recommendations() -> List[str]:
    """è·å–ç¼“å­˜ä¼˜åŒ–å»ºè®®"""
    return [
        "ğŸ”§ æ·»åŠ  continue-on-error: true åˆ°ç¼“å­˜æ­¥éª¤",
        "â±ï¸ ä¸ºç¼“å­˜æ“ä½œè®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´",
        "ğŸ”„ å®ç°é‡è¯•æœºåˆ¶å¤„ç†ä¸´æ—¶ç½‘ç»œé—®é¢˜", 
        "ğŸ“¦ è€ƒè™‘ä½¿ç”¨åˆ†ç¦»çš„ç¼“å­˜æ¢å¤å’Œä¿å­˜æ­¥éª¤",
        "ğŸš€ ä¸ºå…³é”®æ­¥éª¤æ·»åŠ fallbackæœºåˆ¶",
        "ğŸ“Š å¢åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•ä¾¿äºè¯Šæ–­",
        "âš¡ è€ƒè™‘ç¦ç”¨ç¼“å­˜å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨"
    ]


def check_recent_failures() -> Dict[str, any]:
    """æ£€æŸ¥æœ€è¿‘çš„å¤±è´¥æƒ…å†µ"""
    print("ğŸ” æ£€æŸ¥æœ€è¿‘çš„è¿è¡Œæƒ…å†µ...")
    
    # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºæ£€æŸ¥GitHub APIè·å–æœ€è¿‘çš„è¿è¡Œè®°å½•
    # ç›®å‰æä¾›åŸºæœ¬çš„æ£€æŸ¥é€»è¾‘
    
    project_root = Path(__file__).parent.parent
    logs_dir = project_root / "src" / "logs"
    
    recent_info = {
        "has_local_logs": logs_dir.exists(),
        "log_files": [],
        "suggestions": []
    }
    
    if logs_dir.exists():
        log_files = list(logs_dir.glob("*.log"))
        recent_info["log_files"] = [f.name for f in log_files[-5:]]  # æœ€è¿‘5ä¸ªæ—¥å¿—
        
        if not log_files:
            recent_info["suggestions"].append("æ²¡æœ‰æ‰¾åˆ°æœ¬åœ°æ—¥å¿—æ–‡ä»¶")
        else:
            recent_info["suggestions"].append(f"æ‰¾åˆ°{len(log_files)}ä¸ªæ—¥å¿—æ–‡ä»¶")
    else:
        recent_info["suggestions"].append("æœ¬åœ°logsç›®å½•ä¸å­˜åœ¨")
    
    return recent_info


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” GitHub Actionsç¼“å­˜é—®é¢˜è¯Šæ–­å·¥å…·")
    print("=" * 60)
    print(f"ğŸ• è¯Šæ–­æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # 1. æ£€æŸ¥GitHubæœåŠ¡çŠ¶æ€
    github_status = check_github_status()
    print("ğŸ“¡ GitHubæœåŠ¡çŠ¶æ€:")
    print(f"   çŠ¶æ€: {github_status['status']}")
    print(f"   æè¿°: {github_status['description']}")
    print()
    
    # 2. åˆ†æå·¥ä½œæµé…ç½®
    workflow_analysis = analyze_workflow_logs()
    print("ğŸ“‹ å·¥ä½œæµåˆ†æ:")
    print(f"   æ‰¾åˆ°å·¥ä½œæµ: {len(workflow_analysis['workflows_found'])}")
    for wf in workflow_analysis['workflows_found']:
        print(f"     - {wf}")
    
    print(f"   ç¼“å­˜é…ç½®: {len(workflow_analysis['cache_configurations'])}")
    for cache_config in workflow_analysis['cache_configurations']:
        print(f"     - {cache_config['file']}: ç¼“å­˜={cache_config['has_cache']}, "
              f"å®¹é”™={cache_config['has_continue_on_error']}, "
              f"è¶…æ—¶={cache_config['has_timeout']}")
    
    if workflow_analysis['potential_issues']:
        print("   âš ï¸ æ½œåœ¨é—®é¢˜:")
        for issue in workflow_analysis['potential_issues']:
            print(f"     - {issue}")
    print()
    
    # 3. æ£€æŸ¥æœ€è¿‘è¿è¡Œæƒ…å†µ
    recent_info = check_recent_failures()
    print("ğŸ“Š æœ€è¿‘è¿è¡Œæƒ…å†µ:")
    print(f"   æœ¬åœ°æ—¥å¿—: {'å­˜åœ¨' if recent_info['has_local_logs'] else 'ä¸å­˜åœ¨'}")
    if recent_info['log_files']:
        print("   æœ€è¿‘æ—¥å¿—æ–‡ä»¶:")
        for log_file in recent_info['log_files']:
            print(f"     - {log_file}")
    for suggestion in recent_info['suggestions']:
        print(f"   ğŸ’¡ {suggestion}")
    print()
    
    # 4. æä¾›è§£å†³å»ºè®®
    print("ğŸ’¡ ç¼“å­˜ä¼˜åŒ–å»ºè®®:")
    recommendations = get_cache_recommendations()
    for i, rec in enumerate(recommendations, 1):
        print(f"   {i}. {rec}")
    print()
    
    # 5. å¿«é€Ÿä¿®å¤é€‰é¡¹
    print("ğŸš€ å¿«é€Ÿä¿®å¤é€‰é¡¹:")
    print("   1. è¿è¡Œ 'make fix-cache-issues' ä½¿ç”¨äº¤äº’å¼ä¿®å¤å·¥å…·")
    print("   2. æ‰‹åŠ¨åˆ‡æ¢åˆ°ä¼˜åŒ–ç‰ˆæœ¬å·¥ä½œæµ")
    print("   3. ä¸´æ—¶ç¦ç”¨ç¼“å­˜ä½¿ç”¨æœ€å°ç‰ˆæœ¬")
    print("   4. ç­‰å¾…GitHubæœåŠ¡æ¢å¤æ­£å¸¸")
    print()
    
    # 6. æ€»ç»“
    print("ğŸ“ è¯Šæ–­æ€»ç»“:")
    if github_status['status'] != 'none':
        print("   âš ï¸ GitHubæœåŠ¡å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œå»ºè®®ç­‰å¾…æ¢å¤")
    
    if workflow_analysis['potential_issues']:
        print("   ğŸ”§ å·¥ä½œæµé…ç½®éœ€è¦ä¼˜åŒ–")
        print("   ğŸ’¡ å»ºè®®è¿è¡Œ 'make fix-cache-issues' è¿›è¡Œä¿®å¤")
    else:
        print("   âœ… å·¥ä½œæµé…ç½®çœ‹èµ·æ¥æ­£å¸¸")
        print("   ğŸ’¡ é—®é¢˜å¯èƒ½æ˜¯ä¸´æ—¶çš„ç½‘ç»œæˆ–æœåŠ¡é—®é¢˜")
    
    print("\nğŸ”— ç›¸å…³èµ„æº:")
    print("   - GitHubçŠ¶æ€é¡µé¢: https://www.githubstatus.com/")
    print("   - Actionsæ–‡æ¡£: https://docs.github.com/en/actions")
    print("   - ç¼“å­˜æ–‡æ¡£: https://docs.github.com/en/actions/using-workflows/caching-dependencies")


if __name__ == "__main__":
    main() 