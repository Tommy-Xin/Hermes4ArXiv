#!/usr/bin/env python3
# /// script
# requires-python = ">=3.10"
# dependencies = [
#     "openai>=1.0.0",
#     "anthropic>=0.7.0",
#     "google-generativeai>=0.3.0",
#     "requests>=2.31.0",
# ]
# ///
"""
å¤š AI API æ”¯æŒè®¾ç½®è„šæœ¬
è‡ªåŠ¨é…ç½®å’Œæµ‹è¯•å¤šä¸ª AI æä¾›å•†
"""

import os
import sys
import asyncio
from pathlib import Path
from typing import Dict, List, Optional

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))


class AIProviderTester:
    """AI æä¾›å•†æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.providers = {
            'deepseek': {
                'api_key_env': 'DEEPSEEK_API_KEY',
                'base_url': 'https://api.deepseek.com/v1',
                'model': 'deepseek-chat',
                'test_prompt': 'è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æ·±åº¦å­¦ä¹ ã€‚'
            },
            'openai': {
                'api_key_env': 'OPENAI_API_KEY',
                'base_url': 'https://api.openai.com/v1',
                'model': 'gpt-3.5-turbo',
                'test_prompt': 'Briefly explain deep learning.'
            },
            'claude': {
                'api_key_env': 'CLAUDE_API_KEY',
                'base_url': 'https://api.anthropic.com',
                'model': 'claude-3-haiku-20240307',
                'test_prompt': 'Briefly explain deep learning.'
            },
            'gemini': {
                'api_key_env': 'GEMINI_API_KEY',
                'base_url': 'https://generativelanguage.googleapis.com',
                'model': 'gemini-pro',
                'test_prompt': 'Briefly explain deep learning.'
            }
        }
        
        self.test_results = {}
    
    def check_api_keys(self) -> Dict[str, bool]:
        """æ£€æŸ¥ API å¯†é’¥æ˜¯å¦é…ç½®"""
        results = {}
        
        print("ğŸ”‘ æ£€æŸ¥ API å¯†é’¥é…ç½®...")
        for provider, config in self.providers.items():
            api_key = os.getenv(config['api_key_env'])
            has_key = bool(api_key and len(api_key) > 10)
            results[provider] = has_key
            
            status = "âœ…" if has_key else "âŒ"
            print(f"   {provider}: {status} {config['api_key_env']}")
        
        return results
    
    async def test_deepseek(self) -> bool:
        """æµ‹è¯• DeepSeek API"""
        try:
            import requests
            
            api_key = os.getenv('DEEPSEEK_API_KEY')
            if not api_key:
                return False
            
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'deepseek-chat',
                'messages': [
                    {'role': 'user', 'content': 'è¯·ç®€å•ä»‹ç»ä¸€ä¸‹æ·±åº¦å­¦ä¹ ã€‚'}
                ],
                'max_tokens': 100
            }
            
            response = requests.post(
                'https://api.deepseek.com/v1/chat/completions',
                headers=headers,
                json=data,
                timeout=30
            )
            
            return response.status_code == 200
            
        except Exception as e:
            print(f"   DeepSeek æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_openai(self) -> bool:
        """æµ‹è¯• OpenAI API"""
        try:
            import openai
            
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return False
            
            client = openai.OpenAI(api_key=api_key)
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "user", "content": "Briefly explain deep learning."}
                ],
                max_tokens=100
            )
            
            return bool(response.choices[0].message.content)
            
        except Exception as e:
            print(f"   OpenAI æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_claude(self) -> bool:
        """æµ‹è¯• Claude API"""
        try:
            import anthropic
            
            api_key = os.getenv('CLAUDE_API_KEY')
            if not api_key:
                return False
            
            client = anthropic.Anthropic(api_key=api_key)
            
            response = client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=100,
                messages=[
                    {"role": "user", "content": "Briefly explain deep learning."}
                ]
            )
            
            return bool(response.content[0].text)
            
        except Exception as e:
            print(f"   Claude æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_gemini(self) -> bool:
        """æµ‹è¯• Gemini API"""
        try:
            import google.generativeai as genai
            
            api_key = os.getenv('GEMINI_API_KEY')
            if not api_key:
                return False
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel('gemini-pro')
            
            response = model.generate_content("Briefly explain deep learning.")
            
            return bool(response.text)
            
        except Exception as e:
            print(f"   Gemini æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    async def test_all_providers(self) -> Dict[str, bool]:
        """æµ‹è¯•æ‰€æœ‰ AI æä¾›å•†"""
        print("\nğŸ§ª æµ‹è¯• AI æä¾›å•†è¿æ¥...")
        
        test_functions = {
            'deepseek': self.test_deepseek,
            'openai': self.test_openai,
            'claude': self.test_claude,
            'gemini': self.test_gemini
        }
        
        results = {}
        
        for provider, test_func in test_functions.items():
            print(f"   æµ‹è¯• {provider}...")
            try:
                result = await test_func()
                results[provider] = result
                status = "âœ… è¿æ¥æˆåŠŸ" if result else "âŒ è¿æ¥å¤±è´¥"
                print(f"   {provider}: {status}")
            except Exception as e:
                results[provider] = False
                print(f"   {provider}: âŒ æµ‹è¯•å¼‚å¸¸ - {e}")
        
        return results
    
    def generate_config_template(self) -> str:
        """ç”Ÿæˆé…ç½®æ¨¡æ¿"""
        template = """# AI æä¾›å•†é…ç½®æ¨¡æ¿
# å°†æ­¤å†…å®¹æ·»åŠ åˆ° .env æ–‡ä»¶ä¸­

# DeepSeek API (æ¨èï¼Œæ€§ä»·æ¯”é«˜)
DEEPSEEK_API_KEY=sk-your-deepseek-api-key

# OpenAI API (å¯é€‰)
OPENAI_API_KEY=sk-your-openai-api-key

# Claude API (å¯é€‰)
CLAUDE_API_KEY=sk-ant-your-claude-api-key

# Gemini API (å¯é€‰)
GEMINI_API_KEY=your-gemini-api-key

# AI åˆ†æç­–ç•¥é…ç½®
ANALYSIS_STRATEGY=fallback  # fallback, parallel, consensus
AI_FALLBACK_ORDER=deepseek,openai,claude,gemini
"""
        return template
    
    def create_multi_ai_analyzer(self):
        """åˆ›å»ºå¤š AI åˆ†æå™¨ç¤ºä¾‹ä»£ç """
        code = '''# src/ai_analyzer_v2.py - å¤š AI åˆ†æå™¨å®ç°
from abc import ABC, abstractmethod
from enum import Enum
from typing import Dict, List, Optional
import asyncio
import logging

logger = logging.getLogger(__name__)

class AIProvider(Enum):
    DEEPSEEK = "deepseek"
    OPENAI = "openai"
    CLAUDE = "claude"
    GEMINI = "gemini"

class BaseAIAnalyzer(ABC):
    """AI åˆ†æå™¨åŸºç±»"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.is_available_flag = bool(api_key)
    
    @abstractmethod
    async def analyze_paper(self, paper) -> Dict:
        """åˆ†æè®ºæ–‡"""
        pass
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨"""
        return self.is_available_flag
    
    @abstractmethod
    def get_provider_info(self) -> Dict:
        """è·å–æä¾›å•†ä¿¡æ¯"""
        pass

class MultiAIAnalyzer:
    """å¤š AI åˆ†æå™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.analyzers = {}
        self.fallback_order = self._parse_fallback_order()
        self._initialize_analyzers()
    
    def _parse_fallback_order(self) -> List[AIProvider]:
        """è§£æé™çº§é¡ºåº"""
        order_str = self.config.get('AI_FALLBACK_ORDER', 'deepseek,openai,claude,gemini')
        order = []
        for provider_name in order_str.split(','):
            try:
                provider = AIProvider(provider_name.strip())
                order.append(provider)
            except ValueError:
                logger.warning(f"æœªçŸ¥çš„ AI æä¾›å•†: {provider_name}")
        return order
    
    def _initialize_analyzers(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        # è¿™é‡Œä¼šæ ¹æ®é…ç½®åˆå§‹åŒ–å„ä¸ªåˆ†æå™¨
        # å…·ä½“å®ç°ä¼šåœ¨åç»­æ·»åŠ 
        pass
    
    async def analyze_with_fallback(self, paper) -> Dict:
        """ä½¿ç”¨é™çº§ç­–ç•¥åˆ†æè®ºæ–‡"""
        last_error = None
        
        for provider in self.fallback_order:
            analyzer = self.analyzers.get(provider)
            if not analyzer or not analyzer.is_available():
                continue
            
            try:
                logger.info(f"ä½¿ç”¨ {provider.value} åˆ†æè®ºæ–‡: {paper.title[:50]}...")
                result = await analyzer.analyze_paper(paper)
                result['provider'] = provider.value
                return result
                
            except Exception as e:
                last_error = e
                logger.warning(f"{provider.value} åˆ†æå¤±è´¥: {e}")
                continue
        
        raise Exception(f"æ‰€æœ‰ AI æä¾›å•†éƒ½ä¸å¯ç”¨ã€‚æœ€åé”™è¯¯: {last_error}")
    
    async def analyze_with_consensus(self, paper, min_consensus: int = 2) -> Dict:
        """ä½¿ç”¨å…±è¯†ç­–ç•¥åˆ†æè®ºæ–‡"""
        results = []
        
        # å¹¶è¡Œè°ƒç”¨å¤šä¸ª AI
        tasks = []
        for provider in self.fallback_order[:3]:  # æœ€å¤šä½¿ç”¨å‰3ä¸ª
            analyzer = self.analyzers.get(provider)
            if analyzer and analyzer.is_available():
                task = analyzer.analyze_paper(paper)
                tasks.append((provider, task))
        
        # ç­‰å¾…ç»“æœ
        for provider, task in tasks:
            try:
                result = await task
                result['provider'] = provider.value
                results.append(result)
            except Exception as e:
                logger.warning(f"{provider.value} åˆ†æå¤±è´¥: {e}")
        
        if len(results) < min_consensus:
            raise Exception(f"æ— æ³•è¾¾æˆå…±è¯†ï¼Œåªæœ‰ {len(results)} ä¸ªç»“æœ")
        
        # åˆå¹¶ç»“æœï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        return self._merge_results(results)
    
    def _merge_results(self, results: List[Dict]) -> Dict:
        """åˆå¹¶å¤šä¸ªåˆ†æç»“æœ"""
        # è¿™é‡Œå®ç°ç»“æœåˆå¹¶é€»è¾‘
        # å¯ä»¥åŸºäºæŠ•ç¥¨ã€å¹³å‡åˆ†ç­‰ç­–ç•¥
        merged = {
            'providers': [r['provider'] for r in results],
            'consensus_count': len(results),
            'analysis': {}
        }
        
        # ç®€å•åˆå¹¶ç­–ç•¥ï¼šå–ç¬¬ä¸€ä¸ªç»“æœä½œä¸ºä¸»è¦ç»“æœ
        if results:
            merged['analysis'] = results[0].get('analysis', {})
        
        return merged
'''
        
        # å†™å…¥æ–‡ä»¶
        output_file = Path(__file__).parent.parent / "src" / "ai_analyzer_v2.py"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(code)
        
        print(f"âœ… åˆ›å»ºå¤š AI åˆ†æå™¨: {output_file}")
    
    def generate_usage_examples(self) -> str:
        """ç”Ÿæˆä½¿ç”¨ç¤ºä¾‹"""
        examples = """
# ä½¿ç”¨ç¤ºä¾‹

## 1. åŸºæœ¬é…ç½®
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export DEEPSEEK_API_KEY="sk-your-key"
export OPENAI_API_KEY="sk-your-key"
export ANALYSIS_STRATEGY="fallback"
```

## 2. æµ‹è¯• AI è¿æ¥
```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
uv run scripts/setup_multi_ai.py
```

## 3. åœ¨ä»£ç ä¸­ä½¿ç”¨
```python
from ai_analyzer_v2 import MultiAIAnalyzer
from config import Config

# åˆå§‹åŒ–å¤š AI åˆ†æå™¨
config = Config()
analyzer = MultiAIAnalyzer(config.__dict__)

# åˆ†æè®ºæ–‡
result = await analyzer.analyze_with_fallback(paper)
print(f"åˆ†æç»“æœæ¥è‡ª: {result['provider']}")
```

## 4. ä¸åŒç­–ç•¥
- **fallback**: æŒ‰é¡ºåºå°è¯•ï¼Œç¬¬ä¸€ä¸ªæˆåŠŸçš„ç»“æœ
- **parallel**: å¹¶è¡Œè°ƒç”¨å¤šä¸ª AI
- **consensus**: éœ€è¦å¤šä¸ª AI è¾¾æˆå…±è¯†
"""
        return examples


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤š AI API æ”¯æŒè®¾ç½®å‘å¯¼")
    print("=" * 50)
    
    tester = AIProviderTester()
    
    # 1. æ£€æŸ¥ API å¯†é’¥
    key_results = tester.check_api_keys()
    available_count = sum(key_results.values())
    
    print(f"\nğŸ“Š API å¯†é’¥çŠ¶æ€: {available_count}/{len(key_results)} ä¸ªå·²é…ç½®")
    
    if available_count == 0:
        print("\nâš ï¸  æ²¡æœ‰é…ç½®ä»»ä½• API å¯†é’¥ï¼")
        print("\nğŸ“ é…ç½®æ¨¡æ¿:")
        print(tester.generate_config_template())
        return
    
    # 2. æµ‹è¯• API è¿æ¥
    test_results = await tester.test_all_providers()
    working_count = sum(test_results.values())
    
    print(f"\nğŸ“Š API è¿æ¥çŠ¶æ€: {working_count}/{len(test_results)} ä¸ªå¯ç”¨")
    
    # 3. ç”Ÿæˆé…ç½®å»ºè®®
    print("\nğŸ’¡ é…ç½®å»ºè®®:")
    
    working_providers = [p for p, working in test_results.items() if working]
    if working_providers:
        print(f"   âœ… å¯ç”¨çš„ AI æä¾›å•†: {', '.join(working_providers)}")
        print(f"   ğŸ”„ å»ºè®®é™çº§é¡ºåº: {','.join(working_providers)}")
        
        # æ›´æ–°ç¯å¢ƒå˜é‡å»ºè®®
        print(f"\n   å»ºè®®åœ¨ .env ä¸­è®¾ç½®:")
        print(f"   AI_FALLBACK_ORDER={','.join(working_providers)}")
        
        if len(working_providers) >= 2:
            print(f"   ANALYSIS_STRATEGY=consensus  # ä½¿ç”¨å…±è¯†ç­–ç•¥")
        else:
            print(f"   ANALYSIS_STRATEGY=fallback   # ä½¿ç”¨é™çº§ç­–ç•¥")
    
    # 4. åˆ›å»ºç¤ºä¾‹ä»£ç 
    print("\nğŸ”§ åˆ›å»ºå¤š AI åˆ†æå™¨ä»£ç ...")
    tester.create_multi_ai_analyzer()
    
    # 5. æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    print("\nğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
    print(tester.generate_usage_examples())
    
    print("\nğŸ‰ å¤š AI API æ”¯æŒè®¾ç½®å®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥:")
    print("1. æ ¹æ®å»ºè®®é…ç½®ç¯å¢ƒå˜é‡")
    print("2. æ›´æ–° src/config.py æ·»åŠ å¤š AI é…ç½®")
    print("3. åœ¨ src/main.py ä¸­é›†æˆæ–°çš„åˆ†æå™¨")
    print("4. è¿è¡Œæµ‹è¯•éªŒè¯åŠŸèƒ½")


if __name__ == "__main__":
    asyncio.run(main()) 